{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafb43b1-240c-4d08-9f32-a2d5600102cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example file paths\n",
    "file_paths = ['./llama_2000_full.json','./llama3_1000_full.json','./generated_data_3.5_1000.json', './generated_data_4o.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07f6ff-d1a5-4d08-bffd-e145a8b1ea31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Function to load and parse the files\n",
    "def load_files(file_paths):\n",
    "    data = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data.extend(json.load(f))\n",
    "    return data\n",
    "\n",
    "# Function to extract embeddings and configurations\n",
    "def extract_embeddings_and_configs(data):\n",
    "    embeddings = []\n",
    "    configs = []\n",
    "    for item in data:\n",
    "        embeddings.append(item['embedding'])\n",
    "        configs.append(item['configuration'])\n",
    "    return np.array(embeddings), configs\n",
    "\n",
    "# Function to perform clustering\n",
    "def perform_clustering(embeddings, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    return kmeans, labels\n",
    "\n",
    "# Function to calculate the central configuration for each cluster\n",
    "def calculate_central_configs(configs, labels, n_clusters):\n",
    "    config_df = pd.DataFrame(configs)\n",
    "    numeric_columns = config_df.select_dtypes(include=[np.number]).columns\n",
    "    central_configs = config_df.groupby(labels)[numeric_columns].mean().to_dict(orient='records')\n",
    "    return central_configs\n",
    "\n",
    "# Function to visualize clusters\n",
    "def visualize_clusters(embeddings, labels, n_clusters):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster in range(n_clusters):\n",
    "        points = reduced_embeddings[labels == cluster]\n",
    "        plt.scatter(points[:, 0], points[:, 1], label=f'Cluster {cluster}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('Cluster Visualization')\n",
    "    plt.show()\n",
    "\n",
    "# Main analysis function\n",
    "def analyze_clusters(file_paths, n_clusters):\n",
    "    data = load_files(file_paths)\n",
    "    embeddings, configs = extract_embeddings_and_configs(data)\n",
    "    \n",
    "    kmeans, labels = perform_clustering(embeddings, n_clusters)\n",
    "    \n",
    "    central_configs = calculate_central_configs(configs, labels, n_clusters)\n",
    "    silhouette_avg = silhouette_score(embeddings, labels)\n",
    "    \n",
    "    print(f'Silhouette Score: {silhouette_avg}')\n",
    "    print('Central Configurations for each cluster:')\n",
    "    for idx, config in enumerate(central_configs):\n",
    "        print(f'Cluster {idx}: {config}')\n",
    "    \n",
    "    visualize_clusters(embeddings, labels, n_clusters)\n",
    "    \n",
    "    return central_configs\n",
    "\n",
    "\n",
    "# Number of clusters\n",
    "n_clusters = 20\n",
    "\n",
    "# Run the analysis\n",
    "central_configs = analyze_clusters(file_paths, n_clusters)\n",
    "\n",
    "# Save central configurations to a file\n",
    "with open('central_configs.json', 'w') as f:\n",
    "    json.dump(central_configs, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b928008-1ded-42de-8e70-cc3b8df50420",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Function to load and parse the files\n",
    "def load_files(file_paths):\n",
    "    data = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data.extend(json.load(f))\n",
    "    return data\n",
    "\n",
    "# Function to extract embeddings and configurations\n",
    "def extract_embeddings_and_configs(data):\n",
    "    embeddings = []\n",
    "    configs = []\n",
    "    for item in data:\n",
    "        embeddings.append(item['embedding'])\n",
    "        configs.append(item['configuration'])\n",
    "    return np.array(embeddings), configs\n",
    "\n",
    "# Function to perform clustering\n",
    "def perform_clustering(embeddings, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    return kmeans, labels\n",
    "\n",
    "# Function to calculate the central configuration for each cluster, ignoring specified parameters\n",
    "def calculate_central_configs(configs, labels, n_clusters):\n",
    "    config_df = pd.DataFrame(configs)\n",
    "    # Exclude certain columns from the calculations\n",
    "    config_df = config_df.drop(columns=['batch_size', 'max_tokens', 'max_seq_len'])\n",
    "    numeric_columns = config_df.select_dtypes(include=[np.number]).columns\n",
    "    central_configs = config_df.groupby(labels)[numeric_columns].mean().to_dict(orient='records')\n",
    "    return central_configs\n",
    "\n",
    "# Function to visualize clusters\n",
    "def visualize_clusters(embeddings, labels, n_clusters):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster in range(n_clusters):\n",
    "        points = reduced_embeddings[labels == cluster]\n",
    "        plt.scatter(points[:, 0], points[:, 1], label=f'Cluster {cluster}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('Cluster Visualization')\n",
    "    plt.show()\n",
    "\n",
    "# Function to analyze and display details about clusters\n",
    "def display_cluster_details(data, labels):\n",
    "    for i in range(max(labels)+1):\n",
    "        cluster_items = [item['response_content'] for j, item in enumerate(data) if labels[j] == i]\n",
    "        print(f'Cluster {i}:')\n",
    "        print('\\n Responses:', cluster_items[:2])\n",
    "        print('\\n total Responses:', len(cluster_items))\n",
    "        print()\n",
    "\n",
    "# Main analysis function\n",
    "def analyze_clusters(file_paths, n_clusters):\n",
    "    data = load_files(file_paths)\n",
    "    embeddings, configs = extract_embeddings_and_configs(data)\n",
    "    \n",
    "    kmeans, labels = perform_clustering(embeddings, n_clusters)\n",
    "    \n",
    "    central_configs = calculate_central_configs(configs, labels, n_clusters)\n",
    "    silhouette_avg = silhouette_score(embeddings, labels)\n",
    "    \n",
    "    print(f'Silhouette Score: {silhouette_avg}')\n",
    "    print('Central Configurations for each cluster:')\n",
    "    for idx, config in enumerate(central_configs):\n",
    "        print(f'Cluster {idx}: {config}')\n",
    "    \n",
    "    visualize_clusters(embeddings, labels, n_clusters)\n",
    "    display_cluster_details(data, labels)\n",
    "    \n",
    "    return central_configs\n",
    "\n",
    "\"\"\"\n",
    "# Number of clusters\n",
    "n_clusters = 20\n",
    "\n",
    "# Run the analysis\n",
    "central_configs = analyze_clusters(file_paths, n_clusters)\n",
    "\n",
    "# Save central configurations to a file\n",
    "with open('central_configs.json', 'w') as f:\n",
    "    json.dump(central_configs, f, indent=4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6944e-ee1f-4cf4-bf35-1307ce9324a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def load_files(file_paths):\n",
    "    data = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data.extend(json.load(f))\n",
    "    return data\n",
    "\n",
    "def extract_embeddings_and_configs(data):\n",
    "    embeddings = []\n",
    "    configs = []\n",
    "    for item in data:\n",
    "        embeddings.append(item['embedding'])\n",
    "        configs.append(item['configuration'])\n",
    "    return np.array(embeddings), configs\n",
    "\n",
    "def perform_clustering(embeddings, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    return kmeans, labels\n",
    "\n",
    "def calculate_central_configs(configs, labels, n_clusters):\n",
    "    config_df = pd.DataFrame(configs)\n",
    "    config_df = config_df.drop(columns=['batch_size', 'max_tokens', 'max_seq_len'], errors='ignore')\n",
    "    numeric_columns = config_df.select_dtypes(include=[np.number]).columns\n",
    "    central_configs = config_df.groupby(labels)[numeric_columns].mean().to_dict(orient='records')\n",
    "    return central_configs\n",
    "\n",
    "def visualize_clusters(embeddings, labels, n_clusters):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster in range(n_clusters):\n",
    "        points = reduced_embeddings[labels == cluster]\n",
    "        plt.scatter(points[:, 0], points[:, 1], label=f'Cluster {cluster}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('Cluster Visualization')\n",
    "    plt.show()\n",
    "\n",
    "def display_cluster_details(data, labels):\n",
    "    for i in range(max(labels)+1):\n",
    "        cluster_items = [item['response_content'] for j, item in enumerate(data) if labels[j] == i]\n",
    "        print(f'Cluster {i}:')\n",
    "        print('Responses:', cluster_items[:5])  # Displaying first 5 responses for brevity\n",
    "        print('Total Responses:', len(cluster_items))\n",
    "        print()\n",
    "\n",
    "def run_initial_analysis(file_paths, n_clusters):\n",
    "    data = load_files(file_paths)\n",
    "    embeddings, configs = extract_embeddings_and_configs(data)\n",
    "    kmeans, labels = perform_clustering(embeddings, n_clusters)\n",
    "    central_configs = calculate_central_configs(configs, labels, n_clusters)\n",
    "    silhouette_avg = silhouette_score(embeddings, labels)\n",
    "\n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    embeddings_list = embeddings.tolist()\n",
    "    labels_list = labels.tolist()\n",
    "\n",
    "    results = {\n",
    "        'data': data,\n",
    "        'embeddings': embeddings_list,\n",
    "        'configs': configs,\n",
    "        'labels': labels_list,\n",
    "        'central_configs': central_configs,\n",
    "        'silhouette_score': silhouette_avg\n",
    "    }\n",
    "\n",
    "    with open('cluster_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f'Silhouette Score: {silhouette_avg}')\n",
    "    print('Central Configurations for each cluster:')\n",
    "    for idx, config in enumerate(central_configs):\n",
    "        print(f'Cluster {idx}: {config}')\n",
    "\n",
    "    visualize_clusters(embeddings, labels, n_clusters)\n",
    "    display_cluster_details(data, labels)\n",
    "    \n",
    "    return results\n",
    "\n",
    "n_clusters = 15\n",
    "results = run_initial_analysis(file_paths, n_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1676f-2d85-4b39-a8a7-7d31fa03b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_results(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    # Convert lists back to numpy arrays\n",
    "    results['embeddings'] = np.array(results['embeddings'])\n",
    "    results['labels'] = np.array(results['labels'])\n",
    "    return results\n",
    "\n",
    "def save_results(results, filename):\n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    results['embeddings'] = results['embeddings'].tolist()\n",
    "    results['labels'] = results['labels'].tolist()\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "def remove_clusters(data, labels, clusters_to_remove):\n",
    "    filtered_data = [item for i, item in enumerate(data) if labels[i] not in clusters_to_remove]\n",
    "    filtered_embeddings = [embedding for i, embedding in enumerate(results['embeddings']) if labels[i] not in clusters_to_remove]\n",
    "    filtered_labels = [label for label in labels if label not in clusters_to_remove]\n",
    "    return filtered_data, np.array(filtered_embeddings), filtered_labels\n",
    "\n",
    "def recluster_data(embeddings, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    new_labels = kmeans.fit_predict(embeddings)\n",
    "    return kmeans, new_labels\n",
    "\n",
    "def visualize_and_analyze(new_labels, embeddings):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster in range(max(new_labels)+1):\n",
    "        points = reduced_embeddings[new_labels == cluster]\n",
    "        plt.scatter(points[:, 0], points[:, 1], label=f'Cluster {cluster}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('Re-clustered Visualization')\n",
    "    plt.show()\n",
    "\n",
    "def display_cluster_details(data, labels):\n",
    "    for i in range(max(labels)+1):\n",
    "        cluster_items = [item['response_content'] for j, item in enumerate(data) if labels[j] == i]\n",
    "        print(f'Cluster {i}:')\n",
    "        print('Responses:', cluster_items[:2])  # Displaying first 5 responses for brevity\n",
    "        print('Total Responses:', len(cluster_items))\n",
    "        print()\n",
    "\n",
    "# Load previous results\n",
    "results = load_results('cluster_results.json')\n",
    "\n",
    "# Specify clusters to remove\n",
    "clusters_to_remove = [0,2,6]  # Example clusters to remove\n",
    "\n",
    "# Remove specified clusters\n",
    "filtered_data, filtered_embeddings, filtered_labels = remove_clusters(results['data'], results['labels'], clusters_to_remove)\n",
    "\n",
    "# Re-cluster and visualize\n",
    "new_kmeans, new_labels = recluster_data(filtered_embeddings, n_clusters=8)  # Adjust number of clusters if needed\n",
    "visualize_and_analyze(new_labels, filtered_embeddings)\n",
    "display_cluster_details(filtered_data, new_labels)\n",
    "\n",
    "# Save new clustering results\n",
    "results['data'] = filtered_data\n",
    "results['embeddings'] = filtered_embeddings\n",
    "results['labels'] = new_labels\n",
    "results['central_configs'] = calculate_central_configs([config for i, config in enumerate(results['configs']) if results['labels'][i] not in clusters_to_remove], new_labels, n_clusters)\n",
    "\n",
    "save_results(results, 'cluster_results.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60387fe2-e0ba-48cb-b4f7-c281ffa7c797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
