#file input location
Download model:
aws s3 cp s3://sliced-models/llama-2-7b/ /home/ec2-user/environment --recursive
s3://slice-prompt-store/auto-character-generation.json

Set distributed variables:
export RANK=0
export WORLD_SIZE=1
export MASTER_ADDR=127.0.0.1
export MASTER_PORT=29500



python generate.py \
--bucket slice-prompt-store \
--key auto-character-generation.json \
--download_path ./downloaded_file.json \
--model_engine gpt-4 \
--api_key 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


#chatgpt
python generate.py \
--bucket slice-prompt-store \
--key auto-character-generation.json \
--download_path ./downloaded_file.json \
--api_key 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 \
--model_engine gpt-4

#llama7b chat
torchrun --nproc_per_node 1 generate.py \
--bucket slice-prompt-store \
--key auto-character-generation.json \
--download_path ./downloaded_file.json \
--api_key sk- \
--use_llama \
--ckpt_dir /home/ec2-user/environment/models/llama-2-7b-chat \
--tokenizer_path /home/ec2-user/environment/model_training/llama-main/tokenizer.model 

# llama 7b
python generate.py \
--bucket slice-prompt-store \
--key auto-character-generation.json \
--download_path ./downloaded_file.json \
--api_key sk- \
--use_llama \
--ckpt_dir /home/ec2-user/environment/models/llama-2-7b \
--tokenizer_path /home/ec2-user/environment/model_training/llama-main/tokenizer.model

