{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d291d2be-8c54-4784-8378-bc0378424fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16349/157268334.py:57: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = get_cmap('viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAD values saved to train_seq_just_DnD/mad_analysis_output/mad_values.csv\n",
      "MAD plot saved to train_seq_just_DnD/mad_analysis_output/mad_plot.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPTNeoXForCausalLM\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# Define constants\n",
    "experiment = \"train_seq_just_DnD\"\n",
    "MODEL_NAME = \"EleutherAI/pythia-70m\"\n",
    "MODEL_FOLDER = \"/workspace/slice-monorepo/sub_validations/cl_scaling/experiments/train_seq_just_DnD/models\"\n",
    "OUTPUT_FOLDER = os.path.join(experiment, \"mad_analysis_output\")\n",
    "PCA_FOLDER = os.path.join(OUTPUT_FOLDER, 'pca')\n",
    "os.makedirs(PCA_FOLDER, exist_ok=True)\n",
    "\n",
    "# Function to calculate MAD\n",
    "def calculate_mad(weights1, weights2):\n",
    "    return np.mean(np.abs(weights1 - weights2))\n",
    "\n",
    "# Function to perform PCA and save the plot\n",
    "def plot_pca(weights1, weights2, layer_name, batch_num):\n",
    "    try:\n",
    "        if weights1.ndim < 2:\n",
    "            weights1 = weights1.reshape(-1, 1)\n",
    "            weights2 = weights2.reshape(-1, 1)\n",
    "        pca = PCA(n_components=2)\n",
    "        weights = np.concatenate([weights1, weights2], axis=0)\n",
    "        pca_result = pca.fit_transform(weights)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.scatter(pca_result[:len(weights1), 0], pca_result[:len(weights1), 1], alpha=0.5, label='Pre-trained')\n",
    "        plt.scatter(pca_result[len(weights1):, 0], pca_result[len(weights1):, 1], alpha=0.5, label='Fine-tuned')\n",
    "        plt.title(f'PCA of Weights: {layer_name} - Batch {batch_num}')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plot_file = os.path.join(PCA_FOLDER, f'{layer_name.replace(\".\", \"_\")}_batch_{batch_num}_pca.png')\n",
    "        plt.savefig(plot_file)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping PCA for {layer_name} due to error: {e}\")\n",
    "\n",
    "# Load models\n",
    "def load_models(saved_model_path):\n",
    "    model_pretrained = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    model_fine_tuned = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    model_fine_tuned.load_state_dict(torch.load(saved_model_path))\n",
    "    return model_pretrained, model_fine_tuned\n",
    "\n",
    "# Function to analyze models\n",
    "def analyze_models(model_folder):\n",
    "    model_pretrained = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    layer_names = [name for name, _ in model_pretrained.named_parameters() if \"weight\" in name]\n",
    "    mad_values = []\n",
    "\n",
    "    csv_mad_path = os.path.join(OUTPUT_FOLDER, 'mad_values.csv')\n",
    "    cmap = get_cmap('viridis')\n",
    "\n",
    "    if os.path.exists(csv_mad_path):\n",
    "        df_mad = pd.read_csv(csv_mad_path)\n",
    "        print(f'Loaded existing MAD values from {csv_mad_path}')\n",
    "        file_creation_times = df_mad['Batch'].unique()\n",
    "        norm = plt.Normalize(min(file_creation_times), max(file_creation_times))\n",
    "    else:\n",
    "        model_files = [f for f in os.listdir(model_folder) if f.startswith(\"model_epoch\") and f.endswith(\".pt\") and not f.startswith(\"final_model\")]\n",
    "        model_files = sorted(model_files, key=lambda x: os.path.getctime(os.path.join(model_folder, x)))\n",
    "        file_creation_times = [os.path.getctime(os.path.join(model_folder, f)) for f in model_files]\n",
    "        norm = plt.Normalize(min(file_creation_times), max(file_creation_times))\n",
    "\n",
    "        for file_name in model_files:\n",
    "            model_path = os.path.join(model_folder, file_name)\n",
    "            creation_time = os.path.getctime(model_path)\n",
    "            model_fine_tuned = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "            model_fine_tuned.load_state_dict(torch.load(model_path))\n",
    "\n",
    "            # Calculate MAD for all layers\n",
    "            for layer_name in layer_names:\n",
    "                weights_pretrained = model_pretrained.state_dict()[layer_name].cpu().numpy()\n",
    "                weights_fine_tuned = model_fine_tuned.state_dict()[layer_name].cpu().numpy()\n",
    "                mad = calculate_mad(weights_pretrained.flatten(), weights_fine_tuned.flatten())\n",
    "                mad_values.append({'Layer': layer_name, 'MAD': mad, 'Model': file_name, 'Batch': creation_time})\n",
    "        \n",
    "        # Save MAD values to CSV\n",
    "        df_mad = pd.DataFrame(mad_values)\n",
    "        df_mad.to_csv(csv_mad_path, index=False)\n",
    "        print(f'MAD values saved to {csv_mad_path}')\n",
    "\n",
    "    # Plot and save the MAD scatter plot\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    unique_times = sorted(df_mad['Batch'].unique())\n",
    "    selected_times = [unique_times[0], unique_times[len(unique_times)//3], unique_times[2*len(unique_times)//3], unique_times[-1]]\n",
    "    handles = []\n",
    "    labels = []\n",
    "    for creation_time in unique_times:\n",
    "        time_df = df_mad[df_mad['Batch'] == creation_time]\n",
    "        color = cmap(norm(creation_time))\n",
    "        scatter = plt.scatter(range(len(time_df)), time_df['MAD'], color=color, alpha=0.6)\n",
    "        if creation_time in selected_times:\n",
    "            handles.append(scatter)\n",
    "            labels.append(f'Time {creation_time}')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel('MAD')\n",
    "    plt.title('MAD for Each Layer by Creation Time')\n",
    "    plt.legend(handles, labels)\n",
    "    plt.xticks(range(0, len(layer_names), 20))  # Adjusting x-ticks to show every 20th layer index\n",
    "    plt.tight_layout()\n",
    "    plot_mad_path = os.path.join(OUTPUT_FOLDER, 'mad_plot.png')\n",
    "    plt.savefig(plot_mad_path)\n",
    "    plt.close()\n",
    "    print(f'MAD plot saved to {plot_mad_path}')\n",
    "\n",
    "def main():\n",
    "    # Analyze the models for MAD\n",
    "    analyze_models(MODEL_FOLDER)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4cb129-79a2-47d8-9f4d-13dfa0af8c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
