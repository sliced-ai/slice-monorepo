{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff69ae-5a38-4e03-837e-c63a6012721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Configuration Parameters\n",
    "# ---------------------------\n",
    "DATA_FOLDER = './saved_examples'   # Folder containing the data-model pairs\n",
    "TRAIN_RATIO = 0.9         # Ratio of data to use for training\n",
    "NUM_EPOCHS = 100          # Number of training epochs\n",
    "LEARNING_RATE = 1e-4      # Learning rate for the optimizer\n",
    "BATCH_SIZE = 512            # Number of subsets per batch\n",
    "\n",
    "# Target Model Configuration\n",
    "INPUT_SIZE = 784          # Input size (28x28 images flattened)\n",
    "HIDDEN_SIZE = 8           # Hidden size in the target models\n",
    "OUTPUT_SIZE = 10          # Number of classes\n",
    "SUBSET_SIZE = 100         # Number of examples per subset\n",
    "\n",
    "# Calculated Parameters\n",
    "PER_EXAMPLE_INPUT_SIZE = INPUT_SIZE + OUTPUT_SIZE  # 784 + 10 = 794\n",
    "TOTAL_INPUT_SIZE = SUBSET_SIZE * PER_EXAMPLE_INPUT_SIZE  # 100 * 794 = 79,400\n",
    "\n",
    "# Target Model Parameter Size\n",
    "# SimpleNN: (784 * 8 + 8) + (8 * 10 + 10) = 6,280 + 90 = 6,370\n",
    "PARAM_SIZE = (INPUT_SIZE * HIDDEN_SIZE + HIDDEN_SIZE) + (HIDDEN_SIZE * OUTPUT_SIZE + OUTPUT_SIZE)  # 6370\n",
    "\n",
    "# Hypernetwork Configuration\n",
    "NUM_EXAMPLES = SUBSET_SIZE       # Number of examples per subset\n",
    "EMBED_DIM = 256                   # Embedding dimension per example\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Model Definitions\n",
    "# ---------------------------\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Target neural network whose parameters are to be predicted by the hypernetwork.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=784, hidden_size=8, num_layers=1, output_size=10):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(current_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_size = hidden_size\n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class EmbeddingBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Dedicated embedding branch for each input example.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=794, embed_dim=256):\n",
    "        super(EmbeddingBranch, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # Output shape: (batch_size, embed_dim)\n",
    "\n",
    "class FusionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Fusion layer to combine embeddings from all examples using attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=256, num_examples=100):\n",
    "        super(FusionLayer, self).__init__()\n",
    "        self.num_examples = num_examples\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads=8, dropout=0.1)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (sequence_length=num_examples, batch_size, embed_dim)\n",
    "        Returns:\n",
    "            Tensor of shape (sequence_length=num_examples, batch_size, embed_dim)\n",
    "        \"\"\"\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        x = self.layer_norm(x + self.dropout(attn_output))\n",
    "        ff_output = self.feedforward(x)\n",
    "        x = self.layer_norm(x + self.dropout(ff_output))\n",
    "        return x  # Shape: same as input\n",
    "\n",
    "class ParameterGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generates the parameter vector from the fused embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=256, param_size=6370):\n",
    "        super(ParameterGenerator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, param_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # Shape: (batch_size, param_size)\n",
    "\n",
    "class MultiBranchHypernetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Hypernetwork with dedicated embedding branches for each input example.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_examples=100, per_example_input_size=794, embed_dim=256, param_size=6370):\n",
    "        super(MultiBranchHypernetwork, self).__init__()\n",
    "        self.num_examples = num_examples\n",
    "        self.per_example_input_size = per_example_input_size\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Create a list of embedding branches, one for each example\n",
    "        self.embedding_branches = nn.ModuleList([\n",
    "            EmbeddingBranch(input_size=per_example_input_size, embed_dim=embed_dim) for _ in range(num_examples)\n",
    "        ])\n",
    "        \n",
    "        # Fusion layer to combine all embeddings\n",
    "        self.fusion_layer = FusionLayer(embed_dim=embed_dim, num_examples=num_examples)\n",
    "        \n",
    "        # Parameter generator\n",
    "        self.param_generator = ParameterGenerator(embed_dim=embed_dim, param_size=param_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, num_examples * per_example_input_size)\n",
    "        Returns:\n",
    "            param_vector: Tensor of shape (batch_size, param_size)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        # Split the input into individual examples\n",
    "        x = x.view(batch_size, self.num_examples, self.per_example_input_size)  # Shape: (batch_size, num_examples, per_example_input_size)\n",
    "        \n",
    "        # Pass each example through its dedicated embedding branch\n",
    "        embeddings = []\n",
    "        for i in range(self.num_examples):\n",
    "            emb = self.embedding_branches[i](x[:, i, :])  # Shape: (batch_size, embed_dim)\n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Stack embeddings to form a sequence for the fusion layer\n",
    "        embeddings = torch.stack(embeddings, dim=0)  # Shape: (num_examples, batch_size, embed_dim)\n",
    "        \n",
    "        # Apply fusion layer (e.g., attention-based)\n",
    "        fused = self.fusion_layer(embeddings)  # Shape: (num_examples, batch_size, embed_dim)\n",
    "        \n",
    "        # Aggregate transformer outputs: mean pooling over the sequence\n",
    "        aggregated = fused.mean(dim=0)  # Shape: (batch_size, embed_dim)\n",
    "        \n",
    "        # Generate parameter vector\n",
    "        param_vector = self.param_generator(aggregated)  # Shape: (batch_size, param_size)\n",
    "        \n",
    "        return param_vector\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Dataset and DataLoader\n",
    "# ---------------------------\n",
    "\n",
    "class HypernetworkDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Hypernetwork.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): List of tuples (input_vector, param_vector).\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_vector, param_vector = self.data_list[idx]\n",
    "        return input_vector, param_vector\n",
    "\n",
    "def load_data(data_folder):\n",
    "    \"\"\"\n",
    "    Loads the data-model pairs from the specified folder.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Directory containing the saved examples.\n",
    "\n",
    "    Returns:\n",
    "        data_list (list): List of tuples (input_vector, param_vector).\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        if file_name.endswith('.pt'):\n",
    "            file_path = os.path.join(data_folder, file_name)\n",
    "            checkpoint = torch.load(file_path, map_location='cpu')  # Load on CPU to avoid CUDA issues in workers\n",
    "            data = checkpoint['data']   # Tensor of shape (100, 784)\n",
    "            targets = checkpoint['targets']   # Tensor of shape (100)\n",
    "            model_state_dict = checkpoint['model_state_dict']  # Dictionary of model parameters\n",
    "\n",
    "            # Initialize the model and load state_dict\n",
    "            model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to('cpu')  # Initialize on CPU\n",
    "            try:\n",
    "                model.load_state_dict(model_state_dict)\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error loading state_dict for file {file_name}: {e}\")\n",
    "                continue  # Skip this file if there's an error\n",
    "\n",
    "            # Flatten model parameters into a single vector\n",
    "            param_vector = flatten_model_parameters(model)  # Shape: (6370,)\n",
    "\n",
    "            # Flatten data and labels into a single input vector\n",
    "            labels_one_hot = torch.nn.functional.one_hot(targets, num_classes=10).float()  # Shape: (100, 10)\n",
    "            input_vector = torch.cat([data, labels_one_hot], dim=1).view(-1)  # Shape: (100 * 794,) = (79,400,)\n",
    "\n",
    "            data_list.append((input_vector, param_vector))\n",
    "    return data_list\n",
    "\n",
    "def split_data(data_list, train_ratio=TRAIN_RATIO):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets.\n",
    "\n",
    "    Args:\n",
    "        data_list (list): List of data-model pairs.\n",
    "        train_ratio (float): Ratio of data to use for training.\n",
    "\n",
    "    Returns:\n",
    "        train_data (list): Training data.\n",
    "        test_data (list): Test data.\n",
    "    \"\"\"\n",
    "    random.shuffle(data_list)\n",
    "    split_idx = int(len(data_list) * train_ratio)\n",
    "    train_data = data_list[:split_idx]\n",
    "    test_data = data_list[split_idx:]\n",
    "    return train_data, test_data\n",
    "\n",
    "def flatten_model_parameters(model):\n",
    "    \"\"\"\n",
    "    Flattens all parameters of the model into a single vector.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "\n",
    "    Returns:\n",
    "        flat_params (Tensor): Flattened parameter vector.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for param in model.parameters():\n",
    "        params.append(param.view(-1))\n",
    "    return torch.cat(params)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Training and Evaluation Functions\n",
    "# ---------------------------\n",
    "\n",
    "def train_hypernetwork(train_loader, hypernetwork, optimizer, mse_criterion, ce_criterion, epoch):\n",
    "    \"\"\"\n",
    "    Trains the hypernetwork for one epoch using a combined loss function.\n",
    "\n",
    "    Args:\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        hypernetwork (nn.Module): Hypernetwork to generate model parameters.\n",
    "        optimizer (Optimizer): Optimizer for the hypernetwork.\n",
    "        mse_criterion (Loss): Mean Squared Error loss for parameter regression.\n",
    "        ce_criterion (Loss): Cross-Entropy loss for model performance.\n",
    "        epoch (int): Current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        avg_loss (float): Average combined loss over the epoch.\n",
    "        avg_train_acc (float): Average training accuracy over the epoch.\n",
    "    \"\"\"\n",
    "    hypernetwork.train()\n",
    "    total_loss = 0.0\n",
    "    total_train_acc = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    for batch_idx, (input_batch, param_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")):\n",
    "        input_batch = input_batch.to(device)       # Shape: (B, 79,400)\n",
    "        param_batch = param_batch.to(device)       # Shape: (B, 6370)\n",
    "        \n",
    "        # Generate predicted parameters\n",
    "        predicted_params = hypernetwork(input_batch)        # Shape: (B, 6370)\n",
    "        \n",
    "        # Define MSE loss between predicted_params and true params\n",
    "        mse_loss = mse_criterion(predicted_params, param_batch)\n",
    "        \n",
    "        # Initialize a list to hold Cross-Entropy losses\n",
    "        ce_losses = []\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        # Forward pass through each subset in the batch\n",
    "        for i in range(predicted_params.size(0)):\n",
    "            # Load predicted parameters into a new SimpleNN model\n",
    "            generated_model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to(device)\n",
    "            load_parameters_into_model(generated_model, predicted_params[i])  # Shape: (6370,)\n",
    "            \n",
    "            # Extract input data and labels for the subset\n",
    "            subset_input = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, :INPUT_SIZE]  # Shape: (100, 784)\n",
    "            subset_labels = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, INPUT_SIZE:].argmax(dim=1)  # Shape: (100,)\n",
    "            \n",
    "            # Forward pass through the generated model\n",
    "            outputs = generated_model(subset_input)  # Shape: (100, 10)\n",
    "            \n",
    "            # Compute Cross-Entropy loss\n",
    "            ce_loss = ce_criterion(outputs, subset_labels)\n",
    "            ce_losses.append(ce_loss)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == subset_labels).sum().item()\n",
    "            total_predictions += subset_labels.size(0)\n",
    "        \n",
    "        # Aggregate CE losses\n",
    "        ce_loss = torch.stack(ce_losses).mean()\n",
    "        \n",
    "        # Combined loss\n",
    "        combined_loss = mse_loss + ce_loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += combined_loss.item()\n",
    "        total_train_acc += (correct_predictions / total_predictions) * 100  # Percentage\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_train_acc = total_train_acc / num_batches\n",
    "    return avg_loss, avg_train_acc\n",
    "\n",
    "def evaluate_hypernetwork(test_loader, hypernetwork, mse_criterion, ce_criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the hypernetwork on the test data.\n",
    "\n",
    "    Args:\n",
    "        test_loader (DataLoader): DataLoader for test data.\n",
    "        hypernetwork (nn.Module): Hypernetwork to generate model parameters.\n",
    "        mse_criterion (Loss): Mean Squared Error loss for parameter regression.\n",
    "        ce_criterion (Loss): Cross-Entropy loss for model performance.\n",
    "\n",
    "    Returns:\n",
    "        avg_test_loss (float): Average combined loss on the test data.\n",
    "        avg_test_acc (float): Average test accuracy.\n",
    "    \"\"\"\n",
    "    hypernetwork.eval()\n",
    "    total_loss = 0.0\n",
    "    total_test_acc = 0.0\n",
    "    num_batches = len(test_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_batch, param_batch) in enumerate(tqdm(test_loader, desc=\"Evaluating on Test Data\")):\n",
    "            input_batch = input_batch.to(device)       # Shape: (B, 79,400)\n",
    "            param_batch = param_batch.to(device)       # Shape: (B, 6370)\n",
    "            \n",
    "            # Generate predicted parameters\n",
    "            predicted_params = hypernetwork(input_batch)        # Shape: (B, 6370)\n",
    "            \n",
    "            # Define MSE loss between predicted_params and true params\n",
    "            mse_loss = mse_criterion(predicted_params, param_batch)\n",
    "            \n",
    "            # Initialize a list to hold Cross-Entropy losses\n",
    "            ce_losses = []\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            \n",
    "            # Forward pass through each subset in the batch\n",
    "            for i in range(predicted_params.size(0)):\n",
    "                # Load predicted parameters into a new SimpleNN model\n",
    "                generated_model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to(device)\n",
    "                load_parameters_into_model(generated_model, predicted_params[i])  # Shape: (6370,)\n",
    "                \n",
    "                # Extract input data and labels for the subset\n",
    "                subset_input = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, :INPUT_SIZE]  # Shape: (100, 784)\n",
    "                subset_labels = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, INPUT_SIZE:].argmax(dim=1)  # Shape: (100,)\n",
    "                \n",
    "                # Forward pass through the generated model\n",
    "                outputs = generated_model(subset_input)  # Shape: (100, 10)\n",
    "                \n",
    "                # Compute Cross-Entropy loss\n",
    "                ce_loss = ce_criterion(outputs, subset_labels)\n",
    "                ce_losses.append(ce_loss)\n",
    "                \n",
    "                # Compute accuracy\n",
    "                _, predicted_labels = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted_labels == subset_labels).sum().item()\n",
    "                total_predictions += subset_labels.size(0)\n",
    "            \n",
    "            # Aggregate CE losses\n",
    "            ce_loss = torch.stack(ce_losses).mean()\n",
    "            \n",
    "            # Combined loss\n",
    "            combined_loss = mse_loss + ce_loss\n",
    "            \n",
    "            # Accumulate loss and accuracy\n",
    "            total_loss += combined_loss.item()\n",
    "            total_test_acc += (correct_predictions / total_predictions) * 100  # Percentage\n",
    "    \n",
    "    avg_test_loss = total_loss / num_batches\n",
    "    avg_test_acc = total_test_acc / num_batches\n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Utility Functions\n",
    "# ---------------------------\n",
    "def load_parameters_into_model(model, flat_params):\n",
    "    \"\"\"\n",
    "    Loads a flat parameter vector into the model's parameters.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        flat_params (Tensor): Flat parameter vector.\n",
    "    \"\"\"\n",
    "    current_index = 0\n",
    "    for param in model.parameters():\n",
    "        param_size = param.numel()\n",
    "        param.data.copy_(flat_params[current_index:current_index+param_size].view(param.size()))\n",
    "        current_index += param_size\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Main Execution\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    data_list = load_data(DATA_FOLDER)\n",
    "    print(f\"Total data-model pairs loaded: {len(data_list)}\\n\")\n",
    "    \n",
    "    if len(data_list) == 0:\n",
    "        print(\"No data found in the specified DATA_FOLDER. Please ensure that the folder contains .pt files.\")\n",
    "        return\n",
    "    \n",
    "    # Split data\n",
    "    train_data, test_data = split_data(data_list)\n",
    "    print(f\"Training data size: {len(train_data)}, Test data size: {len(test_data)}\\n\")\n",
    "    \n",
    "    # Create Datasets and DataLoaders\n",
    "    train_dataset = HypernetworkDataset(train_data)\n",
    "    test_dataset = HypernetworkDataset(test_data)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=0,  # Set to 0 to avoid CUDA initialization issues\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=0,  # Set to 0 to avoid CUDA initialization issues\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Initialize Hypernetwork\n",
    "    hypernetwork = MultiBranchHypernetwork(\n",
    "        num_examples=NUM_EXAMPLES,\n",
    "        per_example_input_size=PER_EXAMPLE_INPUT_SIZE,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        param_size=PARAM_SIZE\n",
    "    ).to(device)\n",
    "    \n",
    "    # Define loss functions and optimizer\n",
    "    mse_criterion = nn.MSELoss()\n",
    "    ce_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(hypernetwork.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        avg_loss, avg_train_acc = train_hypernetwork(\n",
    "            train_loader, hypernetwork, optimizer, mse_criterion, ce_criterion, epoch\n",
    "        )\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Combined Loss: {avg_loss:.6f}, \"\n",
    "              f\"Training Accuracy: {avg_train_acc:.2f}%\\n\")\n",
    "    \n",
    "    # Final Evaluation on Test Data\n",
    "    final_test_loss, final_test_acc = evaluate_hypernetwork(test_loader, hypernetwork, mse_criterion, ce_criterion)\n",
    "    print(f\"Final Evaluation on Test Data - Combined Loss: {final_test_loss:.6f}, \"\n",
    "          f\"Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    \n",
    "    # Save the trained hypernetwork\n",
    "    save_path = 'trained_multi_branch_hypernetwork.pt'\n",
    "    torch.save({\n",
    "        'hypernetwork_state_dict': hypernetwork.state_dict(),\n",
    "    }, save_path)\n",
    "    print(f\"Hypernetwork training completed and saved to '{save_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea190db-1dba-4533-802e-adb479693122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Configuration Parameters\n",
    "# ---------------------------\n",
    "DATA_FOLDER = './saved_examples'   # Folder containing the data-model pairs\n",
    "TRAIN_RATIO = 0.99         # Ratio of data to use for training\n",
    "NUM_EPOCHS = 100          # Number of training epochs\n",
    "LEARNING_RATE = 1e-4      # Learning rate for the optimizer\n",
    "BATCH_SIZE = 512            # Number of subsets per batch\n",
    "\n",
    "# Target Model Configuration\n",
    "INPUT_SIZE = 784          # Input size (28x28 images flattened)\n",
    "HIDDEN_SIZE = 8           # Hidden size in the target models\n",
    "OUTPUT_SIZE = 10          # Number of classes\n",
    "SUBSET_SIZE = 100         # Number of examples per subset\n",
    "\n",
    "# Calculated Parameters\n",
    "PER_EXAMPLE_INPUT_SIZE = INPUT_SIZE + OUTPUT_SIZE  # 784 + 10 = 794\n",
    "TOTAL_INPUT_SIZE = SUBSET_SIZE * PER_EXAMPLE_INPUT_SIZE  # 100 * 794 = 79,400\n",
    "\n",
    "# Target Model Parameter Size\n",
    "# SimpleNN: (784 * 8 + 8) + (8 * 10 + 10) = 6,280 + 90 = 6,370\n",
    "PARAM_SIZE = (INPUT_SIZE * HIDDEN_SIZE + HIDDEN_SIZE) + (HIDDEN_SIZE * OUTPUT_SIZE + OUTPUT_SIZE)  # 6370\n",
    "\n",
    "# Hypernetwork Configuration\n",
    "NUM_EXAMPLES = SUBSET_SIZE       # Number of examples per subset\n",
    "EMBED_DIM = 256                   # Embedding dimension per example\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Model Definitions\n",
    "# ---------------------------\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Target neural network whose parameters are to be predicted by the hypernetwork.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=784, hidden_size=8, num_layers=1, output_size=10):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(current_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_size = hidden_size\n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class EmbeddingBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Dedicated embedding branch for each input example.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=794, embed_dim=256):\n",
    "        super(EmbeddingBranch, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # Output shape: (batch_size, embed_dim)\n",
    "\n",
    "class FusionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Fusion layer to combine embeddings from all examples using attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=256, num_examples=100):\n",
    "        super(FusionLayer, self).__init__()\n",
    "        self.num_examples = num_examples\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads=8, dropout=0.1)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (sequence_length=num_examples, batch_size, embed_dim)\n",
    "        Returns:\n",
    "            Tensor of shape (sequence_length=num_examples, batch_size, embed_dim)\n",
    "        \"\"\"\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        x = self.layer_norm(x + self.dropout(attn_output))\n",
    "        ff_output = self.feedforward(x)\n",
    "        x = self.layer_norm(x + self.dropout(ff_output))\n",
    "        return x  # Shape: same as input\n",
    "\n",
    "class ParameterGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generates the parameter vector from the fused embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=256, param_size=6370):\n",
    "        super(ParameterGenerator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, param_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # Shape: (batch_size, param_size)\n",
    "\n",
    "class MultiBranchHypernetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Hypernetwork with dedicated embedding branches for each input example.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_examples=100, per_example_input_size=794, embed_dim=256, param_size=6370):\n",
    "        super(MultiBranchHypernetwork, self).__init__()\n",
    "        self.num_examples = num_examples\n",
    "        self.per_example_input_size = per_example_input_size\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Create a list of embedding branches, one for each example\n",
    "        self.embedding_branches = nn.ModuleList([\n",
    "            EmbeddingBranch(input_size=per_example_input_size, embed_dim=embed_dim) for _ in range(num_examples)\n",
    "        ])\n",
    "        \n",
    "        # Fusion layer to combine all embeddings\n",
    "        self.fusion_layer = FusionLayer(embed_dim=embed_dim, num_examples=num_examples)\n",
    "        \n",
    "        # Parameter generator\n",
    "        self.param_generator = ParameterGenerator(embed_dim=embed_dim, param_size=param_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, num_examples * per_example_input_size)\n",
    "        Returns:\n",
    "            param_vector: Tensor of shape (batch_size, param_size)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        # Split the input into individual examples\n",
    "        x = x.view(batch_size, self.num_examples, self.per_example_input_size)  # Shape: (batch_size, num_examples, per_example_input_size)\n",
    "        \n",
    "        # Pass each example through its dedicated embedding branch\n",
    "        embeddings = []\n",
    "        for i in range(self.num_examples):\n",
    "            emb = self.embedding_branches[i](x[:, i, :])  # Shape: (batch_size, embed_dim)\n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Stack embeddings to form a sequence for the fusion layer\n",
    "        embeddings = torch.stack(embeddings, dim=0)  # Shape: (num_examples, batch_size, embed_dim)\n",
    "        \n",
    "        # Apply fusion layer (e.g., attention-based)\n",
    "        fused = self.fusion_layer(embeddings)  # Shape: (num_examples, batch_size, embed_dim)\n",
    "        \n",
    "        # Aggregate transformer outputs: mean pooling over the sequence\n",
    "        aggregated = fused.mean(dim=0)  # Shape: (batch_size, embed_dim)\n",
    "        \n",
    "        # Generate parameter vector\n",
    "        param_vector = self.param_generator(aggregated)  # Shape: (batch_size, param_size)\n",
    "        \n",
    "        return param_vector\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Dataset and DataLoader\n",
    "# ---------------------------\n",
    "\n",
    "class HypernetworkDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Hypernetwork.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): List of tuples (input_vector, param_vector).\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_vector, param_vector = self.data_list[idx]\n",
    "        return input_vector, param_vector\n",
    "\n",
    "def load_data(data_folder):\n",
    "    \"\"\"\n",
    "    Loads the data-model pairs from the specified folder.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Directory containing the saved examples.\n",
    "\n",
    "    Returns:\n",
    "        data_list (list): List of tuples (input_vector, param_vector).\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        if file_name.endswith('.pt'):\n",
    "            file_path = os.path.join(data_folder, file_name)\n",
    "            checkpoint = torch.load(file_path, map_location='cpu')  # Load on CPU to avoid CUDA issues in workers\n",
    "            data = checkpoint['data']   # Tensor of shape (100, 784)\n",
    "            targets = checkpoint['targets']   # Tensor of shape (100)\n",
    "            model_state_dict = checkpoint['model_state_dict']  # Dictionary of model parameters\n",
    "\n",
    "            # Initialize the model and load state_dict\n",
    "            model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to('cpu')  # Initialize on CPU\n",
    "            try:\n",
    "                model.load_state_dict(model_state_dict)\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error loading state_dict for file {file_name}: {e}\")\n",
    "                continue  # Skip this file if there's an error\n",
    "\n",
    "            # Flatten model parameters into a single vector\n",
    "            param_vector = flatten_model_parameters(model)  # Shape: (6370,)\n",
    "\n",
    "            # Flatten data and labels into a single input vector\n",
    "            labels_one_hot = torch.nn.functional.one_hot(targets, num_classes=10).float()  # Shape: (100, 10)\n",
    "            input_vector = torch.cat([data, labels_one_hot], dim=1).view(-1)  # Shape: (100 * 794,) = (79,400,)\n",
    "\n",
    "            data_list.append((input_vector, param_vector))\n",
    "    return data_list\n",
    "\n",
    "def split_data(data_list, train_ratio=TRAIN_RATIO):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets.\n",
    "\n",
    "    Args:\n",
    "        data_list (list): List of data-model pairs.\n",
    "        train_ratio (float): Ratio of data to use for training.\n",
    "\n",
    "    Returns:\n",
    "        train_data (list): Training data.\n",
    "        test_data (list): Test data.\n",
    "    \"\"\"\n",
    "    random.shuffle(data_list)\n",
    "    split_idx = int(len(data_list) * train_ratio)\n",
    "    train_data = data_list[:split_idx]\n",
    "    test_data = data_list[split_idx:]\n",
    "    return train_data, test_data\n",
    "\n",
    "def flatten_model_parameters(model):\n",
    "    \"\"\"\n",
    "    Flattens all parameters of the model into a single vector.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "\n",
    "    Returns:\n",
    "        flat_params (Tensor): Flattened parameter vector.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for param in model.parameters():\n",
    "        params.append(param.view(-1))\n",
    "    return torch.cat(params)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Training and Evaluation Functions\n",
    "# ---------------------------\n",
    "\n",
    "def train_hypernetwork(train_loader, hypernetwork, optimizer, mse_criterion, ce_criterion):\n",
    "    \"\"\"\n",
    "    Trains the hypernetwork for one epoch using a combined loss function.\n",
    "\n",
    "    Args:\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        hypernetwork (nn.Module): Hypernetwork to generate model parameters.\n",
    "        optimizer (Optimizer): Optimizer for the hypernetwork.\n",
    "        mse_criterion (Loss): Mean Squared Error loss for parameter regression.\n",
    "        ce_criterion (Loss): Cross-Entropy loss for model performance.\n",
    "\n",
    "    Returns:\n",
    "        avg_loss (float): Average combined loss over the epoch.\n",
    "        avg_train_acc (float): Average training accuracy over the epoch.\n",
    "    \"\"\"\n",
    "    hypernetwork.train()\n",
    "    total_loss = 0.0\n",
    "    total_train_acc = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    for batch_idx, (input_batch, param_batch) in enumerate(train_loader):\n",
    "        input_batch = input_batch.to(device)       # Shape: (B, 79,400)\n",
    "        param_batch = param_batch.to(device)       # Shape: (B, 6370)\n",
    "        \n",
    "        # Generate predicted parameters\n",
    "        predicted_params = hypernetwork(input_batch)        # Shape: (B, 6370)\n",
    "        \n",
    "        # Define MSE loss between predicted_params and true params\n",
    "        mse_loss = mse_criterion(predicted_params, param_batch)\n",
    "        \n",
    "        # Initialize a list to hold Cross-Entropy losses\n",
    "        ce_losses = []\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        # Forward pass through each subset in the batch\n",
    "        for i in range(predicted_params.size(0)):\n",
    "            # Load predicted parameters into a new SimpleNN model\n",
    "            generated_model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to(device)\n",
    "            load_parameters_into_model(generated_model, predicted_params[i])  # Shape: (6370,)\n",
    "            \n",
    "            # Extract input data and labels for the subset\n",
    "            subset_input = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, :INPUT_SIZE]  # Shape: (100, 784)\n",
    "            subset_labels = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, INPUT_SIZE:].argmax(dim=1)  # Shape: (100,)\n",
    "            \n",
    "            # Forward pass through the generated model\n",
    "            outputs = generated_model(subset_input)  # Shape: (100, 10)\n",
    "            \n",
    "            # Compute Cross-Entropy loss\n",
    "            ce_loss = ce_criterion(outputs, subset_labels)\n",
    "            ce_losses.append(ce_loss)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == subset_labels).sum().item()\n",
    "            total_predictions += subset_labels.size(0)\n",
    "        \n",
    "        # Aggregate CE losses\n",
    "        ce_loss = torch.stack(ce_losses).mean()\n",
    "        \n",
    "        # Combined loss\n",
    "        combined_loss = mse_loss + ce_loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += combined_loss.item()\n",
    "        total_train_acc += (correct_predictions / total_predictions) * 100  # Percentage\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_train_acc = total_train_acc / num_batches\n",
    "    return avg_loss, avg_train_acc\n",
    "\n",
    "def evaluate_hypernetwork(test_loader, hypernetwork, mse_criterion, ce_criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the hypernetwork on the test data.\n",
    "\n",
    "    Args:\n",
    "        test_loader (DataLoader): DataLoader for test data.\n",
    "        hypernetwork (nn.Module): Hypernetwork to generate model parameters.\n",
    "        mse_criterion (Loss): Mean Squared Error loss for parameter regression.\n",
    "        ce_criterion (Loss): Cross-Entropy loss for model performance.\n",
    "\n",
    "    Returns:\n",
    "        avg_test_loss (float): Average combined loss on the test data.\n",
    "        avg_test_acc (float): Average test accuracy.\n",
    "    \"\"\"\n",
    "    hypernetwork.eval()\n",
    "    total_loss = 0.0\n",
    "    total_test_acc = 0.0\n",
    "    num_batches = len(test_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_batch, param_batch) in enumerate(test_loader):\n",
    "            input_batch = input_batch.to(device)       # Shape: (B, 79,400)\n",
    "            param_batch = param_batch.to(device)       # Shape: (B, 6370)\n",
    "            \n",
    "            # Generate predicted parameters\n",
    "            predicted_params = hypernetwork(input_batch)        # Shape: (B, 6370)\n",
    "            \n",
    "            # Define MSE loss between predicted_params and true params\n",
    "            mse_loss = mse_criterion(predicted_params, param_batch)\n",
    "            \n",
    "            # Initialize a list to hold Cross-Entropy losses\n",
    "            ce_losses = []\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            \n",
    "            # Forward pass through each subset in the batch\n",
    "            for i in range(predicted_params.size(0)):\n",
    "                # Load predicted parameters into a new SimpleNN model\n",
    "                generated_model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to(device)\n",
    "                load_parameters_into_model(generated_model, predicted_params[i])  # Shape: (6370,)\n",
    "                \n",
    "                # Extract input data and labels for the subset\n",
    "                subset_input = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, :INPUT_SIZE]  # Shape: (100, 784)\n",
    "                subset_labels = input_batch[i].view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, INPUT_SIZE:].argmax(dim=1)  # Shape: (100,)\n",
    "                \n",
    "                # Forward pass through the generated model\n",
    "                outputs = generated_model(subset_input)  # Shape: (100, 10)\n",
    "                \n",
    "                # Compute Cross-Entropy loss\n",
    "                ce_loss = ce_criterion(outputs, subset_labels)\n",
    "                ce_losses.append(ce_loss)\n",
    "                \n",
    "                # Compute accuracy\n",
    "                _, predicted_labels = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted_labels == subset_labels).sum().item()\n",
    "                total_predictions += subset_labels.size(0)\n",
    "            \n",
    "            # Aggregate CE losses\n",
    "            ce_loss = torch.stack(ce_losses).mean()\n",
    "            \n",
    "            # Combined loss\n",
    "            combined_loss = mse_loss + ce_loss\n",
    "            \n",
    "            # Accumulate loss and accuracy\n",
    "            total_loss += combined_loss.item()\n",
    "            total_test_acc += (correct_predictions / total_predictions) * 100  # Percentage\n",
    "    \n",
    "    avg_test_loss = total_loss / num_batches\n",
    "    avg_test_acc = total_test_acc / num_batches\n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Utility Functions\n",
    "# ---------------------------\n",
    "def load_parameters_into_model(model, flat_params):\n",
    "    \"\"\"\n",
    "    Loads a flat parameter vector into the model's parameters.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        flat_params (Tensor): Flat parameter vector.\n",
    "    \"\"\"\n",
    "    current_index = 0\n",
    "    for param in model.parameters():\n",
    "        param_size = param.numel()\n",
    "        param.data.copy_(flat_params[current_index:current_index+param_size].view(param.size()))\n",
    "        current_index += param_size\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Main Execution\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    data_list = load_data(DATA_FOLDER)\n",
    "    print(f\"Total data-model pairs loaded: {len(data_list)}\\n\")\n",
    "    \n",
    "    if len(data_list) == 0:\n",
    "        print(\"No data found in the specified DATA_FOLDER. Please ensure that the folder contains .pt files.\")\n",
    "        return\n",
    "    \n",
    "    # Split data\n",
    "    train_data, test_data = split_data(data_list)\n",
    "    print(f\"Training data size: {len(train_data)}, Test data size: {len(test_data)}\\n\")\n",
    "    \n",
    "    # Create Datasets and DataLoaders\n",
    "    train_dataset = HypernetworkDataset(train_data)\n",
    "    test_dataset = HypernetworkDataset(test_data)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=0,  # Set to 0 to avoid CUDA initialization issues\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=0,  # Set to 0 to avoid CUDA initialization issues\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Initialize Hypernetwork\n",
    "    hypernetwork = MultiBranchHypernetwork(\n",
    "        num_examples=NUM_EXAMPLES,\n",
    "        per_example_input_size=PER_EXAMPLE_INPUT_SIZE,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        param_size=PARAM_SIZE\n",
    "    ).to(device)\n",
    "    \n",
    "    # Define loss functions and optimizer\n",
    "    mse_criterion = nn.MSELoss()\n",
    "    ce_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(hypernetwork.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        avg_loss, avg_train_acc = train_hypernetwork(\n",
    "            train_loader, hypernetwork, optimizer, mse_criterion, ce_criterion\n",
    "        )\n",
    "        avg_test_loss, avg_test_acc = evaluate_hypernetwork(\n",
    "            test_loader, hypernetwork, mse_criterion, ce_criterion\n",
    "        )\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Loss: {avg_loss:.6f}, \"\n",
    "              f\"Train Acc: {avg_train_acc:.2f}%, Test Acc: {avg_test_acc:.2f}%\")\n",
    "    \n",
    "    # Save the trained hypernetwork\n",
    "    save_path = 'trained_multi_branch_hypernetwork.pt'\n",
    "    torch.save({\n",
    "        'hypernetwork_state_dict': hypernetwork.state_dict(),\n",
    "    }, save_path)\n",
    "    print(f\"\\nHypernetwork training completed and saved to '{save_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b99f23c-2554-4455-82a7-8cc8f85e0887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Total data-model pairs loaded: 547\n",
      "\n",
      "Training data size: 492, Test data size: 55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  51%|█████     | 252/492 [00:16<00:15, 15.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 445\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHypernetwork training completed and saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 426\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m--> 426\u001b[0m     avg_loss, avg_train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_hypernetwork\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypernetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mce_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] - Combined Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# Final Evaluation on Test Data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 300\u001b[0m, in \u001b[0;36mtrain_hypernetwork\u001b[0;34m(train_data, hypernetwork, optimizer, mse_criterion, ce_criterion, epoch)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m    299\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 300\u001b[0m \u001b[43mcombined_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Accumulate loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Configuration Parameters\n",
    "# ---------------------------\n",
    "DATA_FOLDER = './large'   # Folder containing the data-model pairs\n",
    "TRAIN_RATIO = 0.9                  # Ratio of data to use for training\n",
    "NUM_EPOCHS = 100                    # Number of training epochs\n",
    "LEARNING_RATE = 1e-4               # Learning rate for the optimizer\n",
    "\n",
    "# Target Model Configuration\n",
    "INPUT_SIZE = 784                   # Input size (28x28 images flattened)\n",
    "HIDDEN_SIZE = 8                    # Hidden size in the target models\n",
    "OUTPUT_SIZE = 10                   # Number of classes\n",
    "SUBSET_SIZE = 100                  # Number of examples per subset\n",
    "\n",
    "# Calculated Parameters\n",
    "PER_EXAMPLE_INPUT_SIZE = INPUT_SIZE + OUTPUT_SIZE  # 784 + 10 = 794\n",
    "TOTAL_INPUT_SIZE = SUBSET_SIZE * PER_EXAMPLE_INPUT_SIZE  # 100 * 794 = 79,400\n",
    "\n",
    "# Target Model Parameter Size\n",
    "# SimpleNN: (784 * 8 + 8) + (8 * 10 + 10) = 6,280 + 90 = 6,370\n",
    "PARAM_SIZE = (INPUT_SIZE * HIDDEN_SIZE + HIDDEN_SIZE) + (HIDDEN_SIZE * OUTPUT_SIZE + OUTPUT_SIZE)  # 6370\n",
    "\n",
    "# Hypernetwork Configuration\n",
    "NUM_EXAMPLES = SUBSET_SIZE       # Number of examples per subset\n",
    "EMBED_DIM = 256                   # Embedding dimension per example\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Model Definitions\n",
    "# ---------------------------\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Target neural network whose parameters are to be predicted by the hypernetwork.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=784, hidden_size=8, num_layers=1, output_size=10):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(current_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_size = hidden_size\n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class EmbeddingBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Dedicated embedding branch for each input example.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=794, embed_dim=256):\n",
    "        super(EmbeddingBranch, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # Output shape: (batch_size, embed_dim)\n",
    "\n",
    "class FusionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Fusion layer to combine embeddings from all examples using attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=256, num_examples=100):\n",
    "        super(FusionLayer, self).__init__()\n",
    "        self.num_examples = num_examples\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads=8, dropout=0.1)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (sequence_length=num_examples, batch_size, embed_dim)\n",
    "        Returns:\n",
    "            Tensor of shape (sequence_length=num_examples, batch_size, embed_dim)\n",
    "        \"\"\"\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        x = self.layer_norm(x + self.dropout(attn_output))\n",
    "        ff_output = self.feedforward(x)\n",
    "        x = self.layer_norm(x + self.dropout(ff_output))\n",
    "        return x  # Shape: same as input\n",
    "\n",
    "class ParameterGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generates the parameter vector from the fused embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=256, param_size=6370):\n",
    "        super(ParameterGenerator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, param_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # Shape: (batch_size, param_size)\n",
    "\n",
    "class MultiBranchHypernetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Hypernetwork with dedicated embedding branches for each input example.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_examples=100, per_example_input_size=794, embed_dim=256, param_size=6370):\n",
    "        super(MultiBranchHypernetwork, self).__init__()\n",
    "        self.num_examples = num_examples\n",
    "        self.per_example_input_size = per_example_input_size\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Create a list of embedding branches, one for each example\n",
    "        self.embedding_branches = nn.ModuleList([\n",
    "            EmbeddingBranch(input_size=per_example_input_size, embed_dim=embed_dim) for _ in range(num_examples)\n",
    "        ])\n",
    "        \n",
    "        # Fusion layer to combine all embeddings\n",
    "        self.fusion_layer = FusionLayer(embed_dim=embed_dim, num_examples=num_examples)\n",
    "        \n",
    "        # Parameter generator\n",
    "        self.param_generator = ParameterGenerator(embed_dim=embed_dim, param_size=param_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, num_examples * per_example_input_size)\n",
    "        Returns:\n",
    "            param_vector: Tensor of shape (batch_size, param_size)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        # Split the input into individual examples\n",
    "        x = x.view(batch_size, self.num_examples, self.per_example_input_size)  # Shape: (batch_size, num_examples, per_example_input_size)\n",
    "        \n",
    "        # Pass each example through its dedicated embedding branch\n",
    "        embeddings = []\n",
    "        for i in range(self.num_examples):\n",
    "            emb = self.embedding_branches[i](x[:, i, :])  # Shape: (batch_size, embed_dim)\n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Stack embeddings to form a sequence for the fusion layer\n",
    "        embeddings = torch.stack(embeddings, dim=0)  # Shape: (num_examples, batch_size, embed_dim)\n",
    "        \n",
    "        # Apply fusion layer (e.g., attention-based)\n",
    "        fused = self.fusion_layer(embeddings)  # Shape: (num_examples, batch_size, embed_dim)\n",
    "        \n",
    "        # Aggregate transformer outputs: mean pooling over the sequence\n",
    "        aggregated = fused.mean(dim=0)  # Shape: (batch_size, embed_dim)\n",
    "        \n",
    "        # Generate parameter vector\n",
    "        param_vector = self.param_generator(aggregated)  # Shape: (batch_size, param_size)\n",
    "        \n",
    "        return param_vector\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Data Loading Functions\n",
    "# ---------------------------\n",
    "def load_data(data_folder):\n",
    "    \"\"\"\n",
    "    Loads the data-model pairs from the specified folder.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Directory containing the saved examples.\n",
    "\n",
    "    Returns:\n",
    "        data_list (list): List of tuples (input_vector, param_vector).\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        if file_name.endswith('.pt'):\n",
    "            file_path = os.path.join(data_folder, file_name)\n",
    "            checkpoint = torch.load(file_path, map_location=device)\n",
    "            data = checkpoint['data']   # Tensor of shape (100, 784)\n",
    "            targets = checkpoint['targets']   # Tensor of shape (100)\n",
    "            model_state_dict = checkpoint['model_state_dict']  # Dictionary of model parameters\n",
    "\n",
    "            # Initialize the model and load state_dict\n",
    "            model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to(device)\n",
    "            try:\n",
    "                model.load_state_dict(model_state_dict)\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error loading state_dict for file {file_name}: {e}\")\n",
    "                continue  # Skip this file if there's an error\n",
    "\n",
    "            # Flatten model parameters into a single vector\n",
    "            param_vector = flatten_model_parameters(model)  # Shape: (6370,)\n",
    "\n",
    "            # Flatten data and labels into a single input vector\n",
    "            labels_one_hot = torch.nn.functional.one_hot(targets, num_classes=10).float()  # Shape: (100, 10)\n",
    "            input_vector = torch.cat([data, labels_one_hot], dim=1).view(-1)  # Shape: (100 * 794,) = (79,400,)\n",
    "\n",
    "            data_list.append((input_vector, param_vector))\n",
    "    return data_list\n",
    "\n",
    "def split_data(data_list, train_ratio=TRAIN_RATIO):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets.\n",
    "\n",
    "    Args:\n",
    "        data_list (list): List of data-model pairs.\n",
    "        train_ratio (float): Ratio of data to use for training.\n",
    "\n",
    "    Returns:\n",
    "        train_data (list): Training data.\n",
    "        test_data (list): Test data.\n",
    "    \"\"\"\n",
    "    random.shuffle(data_list)\n",
    "    split_idx = int(len(data_list) * train_ratio)\n",
    "    train_data = data_list[:split_idx]\n",
    "    test_data = data_list[split_idx:]\n",
    "    return train_data, test_data\n",
    "\n",
    "def flatten_model_parameters(model):\n",
    "    \"\"\"\n",
    "    Flattens all parameters of the model into a single vector.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "\n",
    "    Returns:\n",
    "        flat_params (Tensor): Flattened parameter vector.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for param in model.parameters():\n",
    "        params.append(param.view(-1))\n",
    "    return torch.cat(params)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Training and Evaluation Functions\n",
    "# ---------------------------\n",
    "def train_hypernetwork(train_data, hypernetwork, optimizer, mse_criterion, ce_criterion, epoch):\n",
    "    \"\"\"\n",
    "    Trains the hypernetwork for one epoch using a combined loss function.\n",
    "\n",
    "    Args:\n",
    "        train_data (list): List of training data-model pairs.\n",
    "        hypernetwork (nn.Module): Hypernetwork to generate model parameters.\n",
    "        optimizer (Optimizer): Optimizer for the hypernetwork.\n",
    "        mse_criterion (Loss): Mean Squared Error loss for parameter regression.\n",
    "        ce_criterion (Loss): Cross-Entropy loss for model performance.\n",
    "        epoch (int): Current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        avg_loss (float): Average combined loss over the epoch.\n",
    "        avg_train_acc (float): Average training accuracy over the epoch.\n",
    "    \"\"\"\n",
    "    hypernetwork.train()\n",
    "    total_loss = 0.0\n",
    "    total_train_acc = 0.0\n",
    "    num_batches = len(train_data)\n",
    "    \n",
    "    for idx in tqdm(range(len(train_data)), desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        input_vector, param_vector = train_data[idx]\n",
    "        input_vector = input_vector.to(device).unsqueeze(0)  # Shape: (1, 79,400)\n",
    "        param_vector = param_vector.to(device)               # Shape: (6370,)\n",
    "        \n",
    "        # Generate predicted parameters\n",
    "        predicted_params = hypernetwork(input_vector)        # Shape: (1, 6370)\n",
    "        predicted_params = predicted_params.squeeze(0)       # Shape: (6370,)\n",
    "        \n",
    "        # Initialize a new SimpleNN model and load predicted parameters\n",
    "        generated_model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to(device)\n",
    "        load_parameters_into_model(generated_model, predicted_params)\n",
    "        \n",
    "        # Define MSE loss between predicted_params and true params\n",
    "        mse_loss = mse_criterion(predicted_params, param_vector)\n",
    "        \n",
    "        # Extract input data and labels from the input_vector\n",
    "        input_data = input_vector.view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, :INPUT_SIZE]  # Shape: (100, 784)\n",
    "        labels = input_vector.view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, INPUT_SIZE:].argmax(dim=1)  # Shape: (100,)\n",
    "        \n",
    "        # Forward pass through the generated model\n",
    "        outputs = generated_model(input_data)  # Shape: (100, 10)\n",
    "        \n",
    "        # Compute Cross-Entropy loss\n",
    "        ce_loss = ce_criterion(outputs, labels)\n",
    "        \n",
    "        # Combined loss\n",
    "        combined_loss = mse_loss + ce_loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_loss += combined_loss.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        train_acc = (predicted_labels == labels).sum().item() / labels.size(0)\n",
    "        total_train_acc += train_acc\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_train_acc = (total_train_acc / num_batches) * 100  # Percentage\n",
    "    return avg_loss, avg_train_acc\n",
    "\n",
    "def evaluate_hypernetwork(test_data, hypernetwork, mse_criterion, ce_criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the hypernetwork on the test data.\n",
    "\n",
    "    Args:\n",
    "        test_data (list): List of test data-model pairs.\n",
    "        hypernetwork (nn.Module): Hypernetwork to generate model parameters.\n",
    "        mse_criterion (Loss): Mean Squared Error loss for parameter regression.\n",
    "        ce_criterion (Loss): Cross-Entropy loss for model performance.\n",
    "\n",
    "    Returns:\n",
    "        avg_test_loss (float): Average combined loss on the test data.\n",
    "        avg_test_acc (float): Average test accuracy.\n",
    "    \"\"\"\n",
    "    hypernetwork.eval()\n",
    "    total_loss = 0.0\n",
    "    total_test_acc = 0.0\n",
    "    num_batches = len(test_data)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm(range(len(test_data)), desc=\"Evaluating on Test Data\"):\n",
    "            input_vector, param_vector = test_data[idx]\n",
    "            input_vector = input_vector.to(device).unsqueeze(0)  # Shape: (1, 79,400)\n",
    "            param_vector = param_vector.to(device)               # Shape: (6370,)\n",
    "            \n",
    "            # Generate predicted parameters\n",
    "            predicted_params = hypernetwork(input_vector)        # Shape: (1, 6370)\n",
    "            predicted_params = predicted_params.squeeze(0)       # Shape: (6370,)\n",
    "            \n",
    "            # Initialize a new SimpleNN model and load predicted parameters\n",
    "            generated_model = SimpleNN(input_size=784, hidden_size=8, num_layers=1, output_size=10).to(device)\n",
    "            load_parameters_into_model(generated_model, predicted_params)\n",
    "            \n",
    "            # Define MSE loss between predicted_params and true params\n",
    "            mse_loss = mse_criterion(predicted_params, param_vector)\n",
    "            \n",
    "            # Extract input data and labels from the input_vector\n",
    "            input_data = input_vector.view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, :INPUT_SIZE]  # Shape: (100, 784)\n",
    "            labels = input_vector.view(SUBSET_SIZE, PER_EXAMPLE_INPUT_SIZE)[:, INPUT_SIZE:].argmax(dim=1)  # Shape: (100,)\n",
    "            \n",
    "            # Forward pass through the generated model\n",
    "            outputs = generated_model(input_data)  # Shape: (100, 10)\n",
    "            \n",
    "            # Compute Cross-Entropy loss\n",
    "            ce_loss = ce_criterion(outputs, labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            combined_loss = mse_loss + ce_loss\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_loss += combined_loss.item()\n",
    "            \n",
    "            # Compute test accuracy\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            test_acc = (predicted_labels == labels).sum().item() / labels.size(0)\n",
    "            total_test_acc += test_acc\n",
    "    \n",
    "    avg_test_loss = total_loss / num_batches\n",
    "    avg_test_acc = (total_test_acc / num_batches) * 100  # Percentage\n",
    "    \n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Utility Functions\n",
    "# ---------------------------\n",
    "def load_parameters_into_model(model, flat_params):\n",
    "    \"\"\"\n",
    "    Loads a flat parameter vector into the model's parameters.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        flat_params (Tensor): Flat parameter vector.\n",
    "    \"\"\"\n",
    "    current_index = 0\n",
    "    for param in model.parameters():\n",
    "        param_size = param.numel()\n",
    "        param.data.copy_(flat_params[current_index:current_index+param_size].view(param.size()))\n",
    "        current_index += param_size\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Main Execution\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    data_list = load_data(DATA_FOLDER)\n",
    "    print(f\"Total data-model pairs loaded: {len(data_list)}\\n\")\n",
    "    \n",
    "    if len(data_list) == 0:\n",
    "        print(\"No data found in the specified DATA_FOLDER. Please ensure that the folder contains .pt files.\")\n",
    "        return\n",
    "    \n",
    "    # Split data\n",
    "    train_data, test_data = split_data(data_list)\n",
    "    print(f\"Training data size: {len(train_data)}, Test data size: {len(test_data)}\\n\")\n",
    "    \n",
    "    # Initialize Hypernetwork\n",
    "    hypernetwork = MultiBranchHypernetwork(\n",
    "        num_examples=NUM_EXAMPLES,\n",
    "        per_example_input_size=PER_EXAMPLE_INPUT_SIZE,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        param_size=PARAM_SIZE\n",
    "    ).to(device)\n",
    "    \n",
    "    # Define loss functions and optimizer\n",
    "    mse_criterion = nn.MSELoss()\n",
    "    ce_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(hypernetwork.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        avg_loss, avg_train_acc = train_hypernetwork(\n",
    "            train_data, hypernetwork, optimizer, mse_criterion, ce_criterion, epoch\n",
    "        )\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Combined Loss: {avg_loss:.6f}, \"\n",
    "              f\"Training Accuracy: {avg_train_acc:.2f}%\\n\")\n",
    "    \n",
    "    # Final Evaluation on Test Data\n",
    "    final_test_loss, final_test_acc = evaluate_hypernetwork(test_data, hypernetwork, mse_criterion, ce_criterion)\n",
    "    print(f\"Final Evaluation on Test Data - Combined Loss: {final_test_loss:.6f}, \"\n",
    "          f\"Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    \n",
    "    # Save the trained hypernetwork\n",
    "    save_path = 'trained_multi_branch_hypernetwork.pt'\n",
    "    torch.save({\n",
    "        'hypernetwork_state_dict': hypernetwork.state_dict(),\n",
    "    }, save_path)\n",
    "    print(f\"Hypernetwork training completed and saved to '{save_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f004a3c-808d-49da-859d-4d59832107a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
