{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090f3e6f-1ed0-4cc2-bb02-432f1da5bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading CIFAR-10 dataset...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Converting training data to tensors and moving to GPU...\n",
      "Converting test data to tensors and moving to GPU...\n",
      "Data loading complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/30: 100%|██████████| 12/12 [00:07<00:00,  1.51it/s, acc=14.9, loss=3.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 10.00%\n",
      "\n",
      "Best model saved with clean accuracy: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=16.9, loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 11.73%\n",
      "\n",
      "Best model saved with clean accuracy: 11.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=25.8, loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 17.95%\n",
      "\n",
      "Best model saved with clean accuracy: 17.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=31.4, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 30.18%\n",
      "\n",
      "Best model saved with clean accuracy: 30.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=36.5, loss=1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 24.32%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=40.7, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 29.11%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=44.4, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 38.90%\n",
      "\n",
      "Best model saved with clean accuracy: 38.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=48.3, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 45.64%\n",
      "\n",
      "Best model saved with clean accuracy: 45.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=52.1, loss=1.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 49.28%\n",
      "\n",
      "Best model saved with clean accuracy: 49.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=55.2, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 48.15%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=58.8, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 56.25%\n",
      "\n",
      "Best model saved with clean accuracy: 56.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=61.3, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 52.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=63.7, loss=1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 54.55%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=67.2, loss=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 60.79%\n",
      "\n",
      "Best model saved with clean accuracy: 60.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=70.2, loss=0.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 62.17%\n",
      "\n",
      "Best model saved with clean accuracy: 62.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=75.3, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 69.36%\n",
      "\n",
      "Best model saved with clean accuracy: 69.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=77.4, loss=0.646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 69.82%\n",
      "\n",
      "Best model saved with clean accuracy: 69.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=78.6, loss=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.41%\n",
      "\n",
      "Best model saved with clean accuracy: 70.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=79.6, loss=0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.12%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=80.4, loss=0.568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.18%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=81.1, loss=0.543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.77%\n",
      "\n",
      "Best model saved with clean accuracy: 70.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=82.3, loss=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.97%\n",
      "\n",
      "Best model saved with clean accuracy: 70.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=83.1, loss=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.71%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=84.2, loss=0.472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.57%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=85.2, loss=0.448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 70.24%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=86.4, loss=0.421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 71.08%\n",
      "\n",
      "Best model saved with clean accuracy: 71.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=86.6, loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 71.06%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=86.8, loss=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 71.26%\n",
      "\n",
      "Best model saved with clean accuracy: 71.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=86.9, loss=0.409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 71.11%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 12/12 [00:07<00:00,  1.55it/s, acc=87.1, loss=0.406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 71.21%\n",
      "\n",
      "Training complete.\n",
      "Best Clean Accuracy: 71.26%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ============================\n",
    "# 1. Setup and Hyperparameters\n",
    "# ============================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 30\n",
    "batch_size = 4096  # Large batch size\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "# ============================\n",
    "# 2. Data Loading and Preprocessing\n",
    "# ============================\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Only normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training and test datasets\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Convert datasets to tensors and move to GPU\n",
    "print(\"Converting training data to tensors and moving to GPU...\")\n",
    "train_inputs = torch.stack([trainset[i][0] for i in range(len(trainset))]).to(device)\n",
    "train_targets = torch.tensor([trainset[i][1] for i in range(len(trainset))]).to(device)\n",
    "\n",
    "print(\"Converting test data to tensors and moving to GPU...\")\n",
    "test_inputs = torch.stack([testset[i][0] for i in range(len(testset))]).to(device)\n",
    "test_targets = torch.tensor([testset[i][1] for i in range(len(testset))]).to(device)\n",
    "\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "# ============================\n",
    "# 3. Model Definition\n",
    "# ============================\n",
    "\n",
    "class ResNet18_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_CIFAR10, self).__init__()\n",
    "        self.model = resnet18(pretrained=False, num_classes=10)\n",
    "        # Modify the first convolution layer for CIFAR-10\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ResNet18_CIFAR10().to(device)\n",
    "\n",
    "# ============================\n",
    "# 4. Optimizer and Scheduler\n",
    "# ============================\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.1)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ============================\n",
    "# 5. Training and Evaluation Functions\n",
    "# ============================\n",
    "\n",
    "def train_baseline(model, train_inputs, train_targets, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Shuffle the data at the beginning of each epoch\n",
    "    perm = torch.randperm(train_inputs.size(0))\n",
    "    shuffled_inputs = train_inputs[perm]\n",
    "    shuffled_targets = train_targets[perm]\n",
    "\n",
    "    num_batches = train_inputs.size(0) // batch_size\n",
    "\n",
    "    loop = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch_idx in loop:\n",
    "        # Create batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = shuffled_inputs[start:end]\n",
    "        targets = shuffled_targets[start:end]\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_postfix(loss=running_loss/(batch_idx+1), acc=100.*correct/total)\n",
    "\n",
    "def evaluate_baseline(model, test_inputs, test_targets):\n",
    "    model.eval()\n",
    "    correct_clean = 0\n",
    "    total_clean = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Clean accuracy\n",
    "        outputs = model(test_inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_clean += test_targets.size(0)\n",
    "        correct_clean += predicted.eq(test_targets).sum().item()\n",
    "\n",
    "    clean_acc = 100. * correct_clean / total_clean\n",
    "\n",
    "    print(f\"\\nClean Accuracy: {clean_acc:.2f}%\\n\")\n",
    "\n",
    "    return clean_acc\n",
    "\n",
    "# ============================\n",
    "# 6. Training Loop\n",
    "# ============================\n",
    "\n",
    "best_clean_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_baseline(model, train_inputs, train_targets, optimizer, epoch)\n",
    "    clean_acc = evaluate_baseline(model, test_inputs, test_targets)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save the best model based on clean accuracy\n",
    "    if clean_acc > best_clean_acc:\n",
    "        best_clean_acc = clean_acc\n",
    "        torch.save(model.state_dict(), \"resnet18_cifar10_baseline_best.pth\")\n",
    "        print(f\"Best model saved with clean accuracy: {best_clean_acc:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best Clean Accuracy: {best_clean_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798cec87-ffc3-4f6e-a2a5-5656dd2df887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Adversarial Accuracy: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adversarial Accuracy on Baseline Model: 16.14%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def pgd_attack(model, images, labels, eps=8/255, alpha=2/255, iters=7):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    ori_images = images.clone().detach()\n",
    "\n",
    "    for i in range(iters):\n",
    "        # Set requires_grad to True for gradient computation\n",
    "        images.requires_grad = True\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect the gradients\n",
    "        grad = images.grad.data\n",
    "\n",
    "        # Update adversarial images\n",
    "        images = images + alpha * torch.sign(grad)\n",
    "\n",
    "        # Clamp perturbations\n",
    "        perturbation = torch.clamp(images - ori_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(ori_images + perturbation, min=0, max=1).detach()\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 7. Evaluating Baseline on Adversarial Examples\n",
    "# ============================\n",
    "\n",
    "def evaluate_baseline_on_adversarial(model, test_inputs, test_targets, eps=8/255, alpha=2/255, pgd_steps=7):\n",
    "    model.eval()\n",
    "    correct_adv = 0\n",
    "    total_adv = 0\n",
    "\n",
    "    # Loop through test data in batches\n",
    "    for i in tqdm(range(0, test_inputs.size(0), batch_size), desc=\"Evaluating Adversarial Accuracy\"):\n",
    "        start = i\n",
    "        end = min(i + batch_size, test_inputs.size(0))\n",
    "        inputs = test_inputs[start:end]\n",
    "        targets = test_targets[start:end]\n",
    "\n",
    "        # Generate adversarial examples using PGD (requires gradients)\n",
    "        adv_inputs = pgd_attack(model, inputs, targets, eps=eps, alpha=alpha, iters=pgd_steps)\n",
    "\n",
    "        # Now evaluate the model on adversarial examples (no need for gradients here)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(adv_inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_adv += targets.size(0)\n",
    "            correct_adv += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Calculate adversarial accuracy\n",
    "    adv_acc = 100. * correct_adv / total_adv\n",
    "    print(f\"\\nAdversarial Accuracy on Baseline Model: {adv_acc:.2f}%\\n\")\n",
    "\n",
    "    return adv_acc\n",
    "\n",
    "\n",
    "# After the baseline model has been trained, test its robustness on adversarial inputs\n",
    "adv_acc_baseline = evaluate_baseline_on_adversarial(model, test_inputs, test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc439fb-0a9f-4af8-8068-da5f81e887e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ============================\n",
    "# 1. Setup and Hyperparameters\n",
    "# ============================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 30\n",
    "batch_size = 4096  # Large batch size\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "pgd_steps = 7\n",
    "pgd_alpha = 2/255\n",
    "pgd_eps = 8/255\n",
    "\n",
    "# ============================\n",
    "# 2. Data Loading and Preprocessing\n",
    "# ============================\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Only normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training and test datasets\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Convert datasets to tensors and move to GPU\n",
    "print(\"Converting training data to tensors and moving to GPU...\")\n",
    "train_inputs = torch.stack([trainset[i][0] for i in range(len(trainset))]).to(device)\n",
    "train_targets = torch.tensor([trainset[i][1] for i in range(len(trainset))]).to(device)\n",
    "\n",
    "print(\"Converting test data to tensors and moving to GPU...\")\n",
    "test_inputs = torch.stack([testset[i][0] for i in range(len(testset))]).to(device)\n",
    "test_targets = torch.tensor([testset[i][1] for i in range(len(testset))]).to(device)\n",
    "\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "# ============================\n",
    "# 3. Model Definition\n",
    "# ============================\n",
    "\n",
    "class ResNet18_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_CIFAR10, self).__init__()\n",
    "        self.model = resnet18(pretrained=False, num_classes=10)\n",
    "        # Modify the first convolution layer for CIFAR-10\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ResNet18_CIFAR10().to(device)\n",
    "\n",
    "# ============================\n",
    "# 4. Optimizer and Scheduler\n",
    "# ============================\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.1)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ============================\n",
    "# 5. PGD Attack Implementation\n",
    "# ============================\n",
    "\n",
    "def pgd_attack(model, images, labels, eps=8/255, alpha=2/255, iters=7):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    ori_images = images.clone().detach()\n",
    "\n",
    "    for i in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = images.grad.data\n",
    "\n",
    "        # Update adversarial images\n",
    "        images = images + alpha * torch.sign(grad)\n",
    "        # Clamp perturbations\n",
    "        perturbation = torch.clamp(images - ori_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(ori_images + perturbation, min=0, max=1).detach()\n",
    "\n",
    "    return images\n",
    "\n",
    "# ============================\n",
    "# 6. Training and Evaluation Functions\n",
    "# ============================\n",
    "\n",
    "def train_adversarial(model, train_inputs, train_targets, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Shuffle the data at the beginning of each epoch\n",
    "    perm = torch.randperm(train_inputs.size(0))\n",
    "    shuffled_inputs = train_inputs[perm]\n",
    "    shuffled_targets = train_targets[perm]\n",
    "\n",
    "    num_batches = train_inputs.size(0) // batch_size\n",
    "\n",
    "    loop = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch_idx in loop:\n",
    "        # Create batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = shuffled_inputs[start:end]\n",
    "        targets = shuffled_targets[start:end]\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_inputs = pgd_attack(model, inputs, targets, eps=pgd_eps, alpha=pgd_alpha, iters=pgd_steps)\n",
    "\n",
    "        # Combine clean and adversarial examples\n",
    "        combined_inputs = torch.cat([inputs, adv_inputs], dim=0)\n",
    "        combined_targets = torch.cat([targets, targets], dim=0)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(combined_inputs)\n",
    "        loss = criterion(outputs, combined_targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += combined_targets.size(0)\n",
    "        correct += predicted.eq(combined_targets).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_postfix(loss=running_loss/(batch_idx+1), acc=100.*correct/total)\n",
    "\n",
    "def evaluate_adversarial(model, test_inputs, test_targets):\n",
    "    model.eval()\n",
    "    correct_clean = 0\n",
    "    total_clean = 0\n",
    "    correct_adv = 0\n",
    "    total_adv = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Clean accuracy\n",
    "        outputs = model(test_inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_clean += test_targets.size(0)\n",
    "        correct_clean += predicted.eq(test_targets).sum().item()\n",
    "\n",
    "    # Evaluate adversarial accuracy\n",
    "    for i in tqdm(range(0, test_inputs.size(0), batch_size), desc=\"Evaluating Adversarial\"):\n",
    "        start = i\n",
    "        end = min(i + batch_size, test_inputs.size(0))\n",
    "        inputs = test_inputs[start:end]\n",
    "        targets = test_targets[start:end]\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_inputs = pgd_attack(model, inputs, targets, eps=pgd_eps, alpha=pgd_alpha, iters=pgd_steps)\n",
    "\n",
    "        # Predict on adversarial examples\n",
    "        outputs = model(adv_inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_adv += targets.size(0)\n",
    "        correct_adv += predicted.eq(targets).sum().item()\n",
    "\n",
    "    clean_acc = 100. * correct_clean / total_clean\n",
    "    adv_acc = 100. * correct_adv / total_adv\n",
    "\n",
    "    print(f\"\\nClean Accuracy: {clean_acc:.2f}%\")\n",
    "    print(f\"Adversarial Accuracy: {adv_acc:.2f}%\\n\")\n",
    "\n",
    "    return clean_acc, adv_acc\n",
    "\n",
    "# ============================\n",
    "# 7. Training Loop\n",
    "# ============================\n",
    "\n",
    "best_adv_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_adversarial(model, train_inputs, train_targets, optimizer, epoch)\n",
    "    clean_acc, adv_acc = evaluate_adversarial(model, test_inputs, test_targets)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save the best model based on adversarial accuracy\n",
    "    if adv_acc > best_adv_acc:\n",
    "        best_adv_acc = adv_acc\n",
    "        torch.save(model.state_dict(), \"resnet18_cifar10_adversarial_best.pth\")\n",
    "        print(f\"Best model saved with adversarial accuracy: {best_adv_acc:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best Adversarial Accuracy: {best_adv_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988975f-59f2-48f3-b041-d4b600916024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
