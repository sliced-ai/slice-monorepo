{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fdf3b7-8067-49a9-a681-1685c70aa7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ============================\n",
    "# 1. Setup and Hyperparameters\n",
    "# ============================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # Ensures deterministic behavior, may slow down training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 30\n",
    "batch_size = 4096  # Large batch size\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "random_percentage = 0.1  # Percentage of parameters to reinitialize (e.g., 0.1 for 10%)\n",
    "\n",
    "# PGD attack parameters for testing\n",
    "pgd_steps = 7\n",
    "pgd_alpha = 2/255\n",
    "pgd_eps = 8/255\n",
    "\n",
    "# ============================\n",
    "# 2. Data Loading and Preprocessing\n",
    "# ============================\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Only normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training and test datasets\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Convert datasets to tensors and move to GPU\n",
    "print(\"Converting training data to tensors and moving to GPU...\")\n",
    "train_inputs = torch.stack([trainset[i][0] for i in range(len(trainset))]).to(device)\n",
    "train_targets = torch.tensor([trainset[i][1] for i in range(len(trainset))]).to(device)\n",
    "\n",
    "print(\"Converting test data to tensors and moving to GPU...\")\n",
    "test_inputs = torch.stack([testset[i][0] for i in range(len(testset))]).to(device)\n",
    "test_targets = torch.tensor([testset[i][1] for i in range(len(testset))]).to(device)\n",
    "\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "# ============================\n",
    "# 3. Model Definition\n",
    "# ============================\n",
    "\n",
    "class ResNet18_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_CIFAR10, self).__init__()\n",
    "        self.model = resnet18(pretrained=False, num_classes=10)\n",
    "        # Modify the first convolution layer for CIFAR-10\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ResNet18_CIFAR10().to(device)\n",
    "\n",
    "# ============================\n",
    "# 4. Optimizer and Scheduler\n",
    "# ============================\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.1)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ============================\n",
    "# 5. Random Reinitialization Function\n",
    "# ============================\n",
    "\n",
    "def random_reinitialize_parameters(model, percentage):\n",
    "    \"\"\"\n",
    "    Randomly reinitialize a percentage of the model's parameters (excluding final layers).\n",
    "    Returns a list of tuples containing parameter references and their original values.\n",
    "    \"\"\"\n",
    "    params_to_reinit = []\n",
    "    original_values = []\n",
    "    \n",
    "    # Collect all parameters except the final layer\n",
    "    parameters = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc' not in name:  # Exclude final fully connected layer\n",
    "            parameters.append((name, param))\n",
    "    \n",
    "    num_params = len(parameters)\n",
    "    num_to_reinit = int(num_params * percentage)\n",
    "    selected_indices = random.sample(range(num_params), num_to_reinit)\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        name, param = parameters[idx]\n",
    "        # Save original values\n",
    "        original_values.append((param, param.data.clone()))\n",
    "        # Reinitialize parameter\n",
    "        if param.dim() > 1:\n",
    "            nn.init.kaiming_normal_(param.data)\n",
    "        else:\n",
    "            nn.init.zeros_(param.data)\n",
    "        # Freeze parameter\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    return original_values\n",
    "\n",
    "def restore_parameters(original_values):\n",
    "    \"\"\"\n",
    "    Restore the original values of parameters and unfreeze them.\n",
    "    \"\"\"\n",
    "    for param, original_value in original_values:\n",
    "        param.data.copy_(original_value)\n",
    "        param.requires_grad = True\n",
    "\n",
    "# ============================\n",
    "# 6. PGD Attack Implementation for Testing\n",
    "# ============================\n",
    "\n",
    "def pgd_attack(model, images, labels, eps=8/255, alpha=2/255, iters=7):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    ori_images = images.clone().detach()\n",
    "\n",
    "    for i in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = images.grad.data\n",
    "\n",
    "        # Update adversarial images\n",
    "        images = images + alpha * torch.sign(grad)\n",
    "        # Clamp perturbations\n",
    "        perturbation = torch.clamp(images - ori_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(ori_images + perturbation, min=0, max=1).detach()\n",
    "\n",
    "    return images\n",
    "\n",
    "# ============================\n",
    "# 7. Training and Evaluation Functions\n",
    "# ============================\n",
    "\n",
    "def train_random_reinit(model, train_inputs, train_targets, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Shuffle the data at the beginning of each epoch\n",
    "    perm = torch.randperm(train_inputs.size(0))\n",
    "    shuffled_inputs = train_inputs[perm]\n",
    "    shuffled_targets = train_targets[perm]\n",
    "\n",
    "    num_batches = train_inputs.size(0) // batch_size\n",
    "\n",
    "    loop = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch_idx in loop:\n",
    "        # Create batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = shuffled_inputs[start:end]\n",
    "        targets = shuffled_targets[start:end]\n",
    "\n",
    "        # Randomly reinitialize parameters and freeze them\n",
    "        original_values = random_reinitialize_parameters(model, random_percentage)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Restore parameters and unfreeze them\n",
    "        restore_parameters(original_values)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_postfix(loss=running_loss/(batch_idx+1), acc=100.*correct/total)\n",
    "\n",
    "def evaluate_random_reinit(model, test_inputs, test_targets):\n",
    "    model.eval()\n",
    "    correct_clean = 0\n",
    "    total_clean = 0\n",
    "    correct_adv = 0\n",
    "    total_adv = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Clean accuracy\n",
    "        outputs = model(test_inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_clean += test_targets.size(0)\n",
    "        correct_clean += predicted.eq(test_targets).sum().item()\n",
    "\n",
    "    # Evaluate adversarial accuracy\n",
    "    for i in tqdm(range(0, test_inputs.size(0), batch_size), desc=\"Evaluating Adversarial\"):\n",
    "        start = i\n",
    "        end = min(i + batch_size, test_inputs.size(0))\n",
    "        inputs = test_inputs[start:end]\n",
    "        targets = test_targets[start:end]\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_inputs = pgd_attack(model, inputs, targets, eps=pgd_eps, alpha=pgd_alpha, iters=pgd_steps)\n",
    "\n",
    "        # Predict on adversarial examples\n",
    "        outputs = model(adv_inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_adv += targets.size(0)\n",
    "        correct_adv += predicted.eq(targets).sum().item()\n",
    "\n",
    "    clean_acc = 100. * correct_clean / total_clean\n",
    "    adv_acc = 100. * correct_adv / total_adv\n",
    "\n",
    "    print(f\"\\nClean Accuracy: {clean_acc:.2f}%\")\n",
    "    print(f\"Adversarial Accuracy: {adv_acc:.2f}%\\n\")\n",
    "\n",
    "    return clean_acc, adv_acc\n",
    "\n",
    "# ============================\n",
    "# 8. Training Loop\n",
    "# ============================\n",
    "\n",
    "best_clean_acc = 0.0\n",
    "best_adv_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_random_reinit(model, train_inputs, train_targets, optimizer, epoch)\n",
    "    clean_acc, adv_acc = evaluate_random_reinit(model, test_inputs, test_targets)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save the best model based on adversarial accuracy\n",
    "    if adv_acc > best_adv_acc:\n",
    "        best_adv_acc = adv_acc\n",
    "        torch.save(model.state_dict(), \"resnet18_cifar10_random_reinit_best.pth\")\n",
    "        print(f\"Best model saved with adversarial accuracy: {best_adv_acc:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best Clean Accuracy: {clean_acc:.2f}%\")\n",
    "print(f\"Best Adversarial Accuracy: {best_adv_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56da9379-d696-4789-a087-02413cb4b689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading CIFAR-10 dataset...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Converting training data to tensors and moving to GPU...\n",
      "Converting test data to tensors and moving to GPU...\n",
      "Data loading complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/30: 100%|██████████| 12/12 [01:02<00:00,  5.17s/it, acc=9.6, loss=3.72] \n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 9.21%\n",
      "Adversarial Accuracy: 8.16%\n",
      "\n",
      "Best model saved with adversarial accuracy: 8.16%\n",
      "Best model saved with clean accuracy: 9.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=11.2, loss=2.96]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 9.25%\n",
      "Adversarial Accuracy: 10.65%\n",
      "\n",
      "Best model saved with adversarial accuracy: 10.65%\n",
      "Best model saved with clean accuracy: 9.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=12, loss=2.3]   \n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 10.74%\n",
      "Adversarial Accuracy: 14.26%\n",
      "\n",
      "Best model saved with adversarial accuracy: 14.26%\n",
      "Best model saved with clean accuracy: 10.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=17.1, loss=2.19]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 15.34%\n",
      "Adversarial Accuracy: 14.17%\n",
      "\n",
      "Best model saved with clean accuracy: 15.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=19.3, loss=2.14]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 19.12%\n",
      "Adversarial Accuracy: 16.07%\n",
      "\n",
      "Best model saved with adversarial accuracy: 16.07%\n",
      "Best model saved with clean accuracy: 19.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=21.8, loss=2.08]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.15%\n",
      "Adversarial Accuracy: 21.26%\n",
      "\n",
      "Best model saved with adversarial accuracy: 21.26%\n",
      "Best model saved with clean accuracy: 22.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=23.8, loss=2.04]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.23%\n",
      "Adversarial Accuracy: 23.40%\n",
      "\n",
      "Best model saved with adversarial accuracy: 23.40%\n",
      "Best model saved with clean accuracy: 22.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=25.9, loss=1.99]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 20.90%\n",
      "Adversarial Accuracy: 21.40%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=27.4, loss=1.95]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 23.22%\n",
      "Adversarial Accuracy: 17.99%\n",
      "\n",
      "Best model saved with clean accuracy: 23.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=28.8, loss=1.91]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 21.30%\n",
      "Adversarial Accuracy: 16.99%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=30.1, loss=1.86]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 25.26%\n",
      "Adversarial Accuracy: 20.14%\n",
      "\n",
      "Best model saved with clean accuracy: 25.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=31.7, loss=1.82]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 26.59%\n",
      "Adversarial Accuracy: 18.53%\n",
      "\n",
      "Best model saved with clean accuracy: 26.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=32.6, loss=1.79]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 25.62%\n",
      "Adversarial Accuracy: 22.52%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=33.5, loss=1.77]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 20.82%\n",
      "Adversarial Accuracy: 20.64%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=34.7, loss=1.74]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 27.21%\n",
      "Adversarial Accuracy: 19.75%\n",
      "\n",
      "Best model saved with clean accuracy: 27.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=35.8, loss=1.71]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 27.32%\n",
      "Adversarial Accuracy: 23.98%\n",
      "\n",
      "Best model saved with adversarial accuracy: 23.98%\n",
      "Best model saved with clean accuracy: 27.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=36.1, loss=1.7]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 26.01%\n",
      "Adversarial Accuracy: 22.40%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=36.3, loss=1.7] \n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 25.39%\n",
      "Adversarial Accuracy: 23.26%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=36.6, loss=1.69]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 24.97%\n",
      "Adversarial Accuracy: 23.10%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=36.6, loss=1.69]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 24.31%\n",
      "Adversarial Accuracy: 22.30%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 12/12 [01:01<00:00,  5.17s/it, acc=37, loss=1.68]  \n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 23.37%\n",
      "Adversarial Accuracy: 22.47%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=37.1, loss=1.68]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.48%\n",
      "Adversarial Accuracy: 22.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=37.5, loss=1.67]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 23.14%\n",
      "Adversarial Accuracy: 21.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=37.5, loss=1.67]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.41%\n",
      "Adversarial Accuracy: 22.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=37.8, loss=1.66]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.93%\n",
      "Adversarial Accuracy: 21.59%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=37.9, loss=1.66]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.75%\n",
      "Adversarial Accuracy: 21.83%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=37.9, loss=1.66]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.69%\n",
      "Adversarial Accuracy: 21.78%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=38, loss=1.65]  \n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.83%\n",
      "Adversarial Accuracy: 21.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=38, loss=1.65]  \n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.68%\n",
      "Adversarial Accuracy: 21.67%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 12/12 [01:01<00:00,  5.16s/it, acc=37.9, loss=1.65]\n",
      "Evaluating Adversarial: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Accuracy: 22.67%\n",
      "Adversarial Accuracy: 21.66%\n",
      "\n",
      "Training complete.\n",
      "Best Clean Accuracy: 27.32%\n",
      "Best Adversarial Accuracy: 23.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ============================\n",
    "# 1. Setup and Hyperparameters\n",
    "# ============================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # Ensures deterministic behavior, may slow down training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 30\n",
    "batch_size = 4096  # Adjust based on your GPU memory\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "random_percentage = 0.01  # Percentage of parameters to reinitialize (e.g., 0.1 for 10%)\n",
    "\n",
    "# PGD attack parameters for training and testing\n",
    "pgd_steps = 7\n",
    "pgd_alpha = 2/255\n",
    "pgd_eps = 8/255\n",
    "\n",
    "# ============================\n",
    "# 2. Data Loading and Preprocessing\n",
    "# ============================\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Only normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training and test datasets\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Convert datasets to tensors and move to GPU\n",
    "print(\"Converting training data to tensors and moving to GPU...\")\n",
    "train_inputs = torch.stack([trainset[i][0] for i in range(len(trainset))]).to(device)\n",
    "train_targets = torch.tensor([trainset[i][1] for i in range(len(trainset))]).to(device)\n",
    "\n",
    "print(\"Converting test data to tensors and moving to GPU...\")\n",
    "test_inputs = torch.stack([testset[i][0] for i in range(len(testset))]).to(device)\n",
    "test_targets = torch.tensor([testset[i][1] for i in range(len(testset))]).to(device)\n",
    "\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "# ============================\n",
    "# 3. Model Definition\n",
    "# ============================\n",
    "\n",
    "class ResNet18_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_CIFAR10, self).__init__()\n",
    "        self.model = resnet18(pretrained=False, num_classes=10)\n",
    "        # Modify the first convolution layer for CIFAR-10\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ResNet18_CIFAR10().to(device)\n",
    "\n",
    "# ============================\n",
    "# 4. Optimizer and Scheduler\n",
    "# ============================\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.1)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ============================\n",
    "# 5. Random Reinitialization Function\n",
    "# ============================\n",
    "\n",
    "def random_reinitialize_parameters(model, percentage):\n",
    "    \"\"\"\n",
    "    Randomly reinitialize a percentage of the model's parameters (excluding final layers).\n",
    "    Returns a list of tuples containing parameter references and their original values.\n",
    "    \"\"\"\n",
    "    params_to_reinit = []\n",
    "    original_values = []\n",
    "    \n",
    "    # Collect all parameters except the final layer\n",
    "    parameters = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc' not in name and 'classifier' not in name:  # Adjust based on model's final layer name\n",
    "            parameters.append((name, param))\n",
    "    \n",
    "    num_params = len(parameters)\n",
    "    num_to_reinit = int(num_params * percentage)\n",
    "    selected_indices = random.sample(range(num_params), num_to_reinit)\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        name, param = parameters[idx]\n",
    "        # Save original values\n",
    "        original_values.append((param, param.data.clone()))\n",
    "        # Reinitialize parameter\n",
    "        if param.dim() > 1:\n",
    "            nn.init.kaiming_normal_(param.data)\n",
    "        else:\n",
    "            nn.init.zeros_(param.data)\n",
    "        # Freeze parameter\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    return original_values\n",
    "\n",
    "def restore_parameters(original_values):\n",
    "    \"\"\"\n",
    "    Restore the original values of parameters and unfreeze them.\n",
    "    \"\"\"\n",
    "    for param, original_value in original_values:\n",
    "        param.data.copy_(original_value)\n",
    "        param.requires_grad = True\n",
    "\n",
    "# ============================\n",
    "# 6. PGD Attack Implementation\n",
    "# ============================\n",
    "\n",
    "def pgd_attack(model, images, labels, eps=8/255, alpha=2/255, iters=7):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    ori_images = images.clone().detach()\n",
    "\n",
    "    for i in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = images.grad.data\n",
    "\n",
    "        # Update adversarial images\n",
    "        images = images + alpha * torch.sign(grad)\n",
    "        # Clamp perturbations\n",
    "        perturbation = torch.clamp(images - ori_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(ori_images + perturbation, min=0, max=1).detach()\n",
    "\n",
    "    return images\n",
    "\n",
    "# ============================\n",
    "# 7. Training and Evaluation Functions\n",
    "# ============================\n",
    "\n",
    "def train_adversarial_random_reinit(model, train_inputs, train_targets, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Shuffle the data at the beginning of each epoch\n",
    "    perm = torch.randperm(train_inputs.size(0))\n",
    "    shuffled_inputs = train_inputs[perm]\n",
    "    shuffled_targets = train_targets[perm]\n",
    "\n",
    "    num_batches = train_inputs.size(0) // batch_size\n",
    "\n",
    "    loop = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch_idx in loop:\n",
    "        # Create batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = shuffled_inputs[start:end]\n",
    "        targets = shuffled_targets[start:end]\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_inputs = pgd_attack(model, inputs, targets, eps=pgd_eps, alpha=pgd_alpha, iters=pgd_steps)\n",
    "\n",
    "        # Randomly reinitialize parameters and freeze them\n",
    "        original_values = random_reinitialize_parameters(model, random_percentage)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass on adversarial examples\n",
    "        outputs = model(adv_inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Restore parameters and unfreeze them\n",
    "        restore_parameters(original_values)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_postfix(loss=running_loss/(batch_idx+1), acc=100.*correct/total)\n",
    "\n",
    "def evaluate_adversarial_random_reinit(model, test_inputs, test_targets):\n",
    "    model.eval()\n",
    "    correct_clean = 0\n",
    "    total_clean = 0\n",
    "    correct_adv = 0\n",
    "    total_adv = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Clean accuracy\n",
    "        outputs = model(test_inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_clean += test_targets.size(0)\n",
    "        correct_clean += predicted.eq(test_targets).sum().item()\n",
    "\n",
    "    # Evaluate adversarial accuracy\n",
    "    for i in tqdm(range(0, test_inputs.size(0), batch_size), desc=\"Evaluating Adversarial\"):\n",
    "        start = i\n",
    "        end = min(i + batch_size, test_inputs.size(0))\n",
    "        inputs = test_inputs[start:end]\n",
    "        targets = test_targets[start:end]\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_inputs = pgd_attack(model, inputs, targets, eps=pgd_eps, alpha=pgd_alpha, iters=pgd_steps)\n",
    "\n",
    "        # Predict on adversarial examples\n",
    "        outputs = model(adv_inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_adv += targets.size(0)\n",
    "        correct_adv += predicted.eq(targets).sum().item()\n",
    "\n",
    "    clean_acc = 100. * correct_clean / total_clean\n",
    "    adv_acc = 100. * correct_adv / total_adv\n",
    "\n",
    "    print(f\"\\nClean Accuracy: {clean_acc:.2f}%\")\n",
    "    print(f\"Adversarial Accuracy: {adv_acc:.2f}%\\n\")\n",
    "\n",
    "    return clean_acc, adv_acc\n",
    "\n",
    "# ============================\n",
    "# 8. Training Loop\n",
    "# ============================\n",
    "\n",
    "best_adv_acc = 0.0\n",
    "best_clean_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_adversarial_random_reinit(model, train_inputs, train_targets, optimizer, epoch)\n",
    "    clean_acc, adv_acc = evaluate_adversarial_random_reinit(model, test_inputs, test_targets)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save the best model based on adversarial accuracy\n",
    "    if adv_acc > best_adv_acc:\n",
    "        best_adv_acc = adv_acc\n",
    "        torch.save(model.state_dict(), \"resnet18_cifar10_adversarial_random_reinit_best.pth\")\n",
    "        print(f\"Best model saved with adversarial accuracy: {best_adv_acc:.2f}%\")\n",
    "\n",
    "    # Optionally, also save based on clean accuracy\n",
    "    if clean_acc > best_clean_acc:\n",
    "        best_clean_acc = clean_acc\n",
    "        torch.save(model.state_dict(), \"resnet18_cifar10_adversarial_random_reinit_best_clean.pth\")\n",
    "        print(f\"Best model saved with clean accuracy: {best_clean_acc:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best Clean Accuracy: {best_clean_acc:.2f}%\")\n",
    "print(f\"Best Adversarial Accuracy: {best_adv_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451bcac-92e1-4195-8c6b-008127528399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
