{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a71eb4-9731-4333-8c1d-7801b9658623",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy umap-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99693b05-0463-4212-b1ec-b326c99f7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "import sys\n",
    "\n",
    "# Function to generate PRNG data\n",
    "def generate_prng_data(num_samples, dimensions):\n",
    "    return np.random.random((num_samples, dimensions))\n",
    "\n",
    "# Function to measure pairwise distances\n",
    "def measure_pairwise_distances(data):\n",
    "    distances = pdist(data, metric='euclidean')\n",
    "    return distances\n",
    "\n",
    "# Function to check for near-duplicate points (cycling or periodicity)\n",
    "def check_for_duplicates(data, tolerance=1e-6):\n",
    "    unique_data = np.unique(np.round(data, decimals=6), axis=0)\n",
    "    return len(data) - len(unique_data)\n",
    "\n",
    "# Function to apply UMAP for dimensionality reduction\n",
    "def apply_umap(data, n_neighbors=15, min_dist=0.1):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)\n",
    "    embedding = reducer.fit_transform(data)\n",
    "    return embedding\n",
    "\n",
    "# Function to visualize the data after UMAP\n",
    "def visualize_umap(embedding, title):\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to detect when PRNG starts to fail\n",
    "def detect_near_collapse(pairwise_distances, duplicate_count, threshold_distance=0.1, threshold_duplicates=10):\n",
    "    # Check if pairwise distances are clustering (i.e., very small distances start to dominate)\n",
    "    distance_collapsing = np.mean(pairwise_distances) < threshold_distance\n",
    "    # Check if duplicate points are appearing in large numbers\n",
    "    duplicate_collapsing = duplicate_count >= threshold_duplicates\n",
    "    return distance_collapsing or duplicate_collapsing\n",
    "\n",
    "# Main function to run the experiment\n",
    "def run_experiment(num_samples=1000, start_dim=2, max_dim=sys.maxsize, collapse_threshold=0.1):\n",
    "    dim = start_dim\n",
    "    collapse_detected = False\n",
    "    iteration = 1\n",
    "    while not collapse_detected and dim < max_dim:\n",
    "        print(f\"Iteration {iteration}: Analyzing {dim}-dimensional data\")\n",
    "\n",
    "        # Step 1: Generate PRNG Data\n",
    "        data = generate_prng_data(num_samples, dim)\n",
    "\n",
    "        # Step 2: Measure Pairwise Distances\n",
    "        distances = measure_pairwise_distances(data)\n",
    "        avg_distance = np.mean(distances)\n",
    "        print(f\"Average pairwise distance in {dim} dimensions: {avg_distance:.5f}\")\n",
    "\n",
    "        # Step 3: Check for duplicates (to detect periodicity)\n",
    "        duplicate_count = check_for_duplicates(data)\n",
    "        print(f\"Number of near-duplicate points in {dim} dimensions: {duplicate_count}\")\n",
    "\n",
    "        # Step 4: Apply UMAP for visualization\n",
    "        embedding = apply_umap(data)\n",
    "        visualize_umap(embedding, f\"UMAP projection of {dim}D data to 2D\")\n",
    "\n",
    "        # Step 5: Check for collapse\n",
    "        collapse_detected = detect_near_collapse(distances, duplicate_count, threshold_distance=collapse_threshold)\n",
    "        if collapse_detected:\n",
    "            print(f\"Collapse detected at {dim} dimensions!\")\n",
    "            break\n",
    "\n",
    "        print(\"------------\\n\")\n",
    "\n",
    "        # Step 6: Exponentially increase the number of dimensions\n",
    "        dim *= 2\n",
    "        iteration += 1\n",
    "\n",
    "# Run the experiment with exponentially increasing dimensions\n",
    "run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ef660-ade3-4416-962d-fbb63ded6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Function to generate PRNG data at 1 trillion dimensions\n",
    "def generate_prng_data(num_samples, dimensions):\n",
    "    return np.random.random((num_samples, dimensions))\n",
    "\n",
    "# Function to measure variance across dimensions\n",
    "def measure_variance(data):\n",
    "    return np.var(data, axis=0)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(data):\n",
    "    hist, _ = np.histogram(data, bins=50, density=True)\n",
    "    return entropy(hist)\n",
    "\n",
    "# Main function to run the analysis at 1 trillion dimensions\n",
    "def analyze_1_trillion_dimensions(num_samples=1000, dimensions=int(1e8)):\n",
    "    print(f\"Analyzing PRNG data with {dimensions} dimensions and {num_samples} samples\")\n",
    "\n",
    "    # Step 1: Generate PRNG Data\n",
    "    data = generate_prng_data(num_samples, dimensions)\n",
    "    print(\"Data generation complete.\")\n",
    "\n",
    "    # Step 2: Measure Variance Across Dimensions\n",
    "    variances = measure_variance(data)\n",
    "    avg_variance = np.mean(variances)\n",
    "    print(f\"Average variance in {dimensions} dimensions: {avg_variance:.5f}\")\n",
    "\n",
    "    # Step 3: Calculate Entropy\n",
    "    entropy_value = calculate_entropy(data.flatten())\n",
    "    print(f\"Entropy in {dimensions} dimensions: {entropy_value:.5f}\")\n",
    "\n",
    "    print(\"Analysis complete.\")\n",
    "\n",
    "# Run the analysis with 1 trillion dimensions\n",
    "analyze_1_trillion_dimensions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403181af-c632-4f85-8cb6-df2ac73f8c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period detected after generating 82400000 values!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to detect the period of a PRNG by finding repetitions\n",
    "def detect_prng_period(num_values, chunk_size=100000):\n",
    "    seen = set()  # Set to track unique generated values\n",
    "    prng = np.random.default_rng()  # Modern PRNG from numpy\n",
    "    \n",
    "    for i in range(0, num_values, chunk_size):\n",
    "        values = prng.random(chunk_size)  # Generate a chunk of random values\n",
    "        for value in values:\n",
    "            if value in seen:\n",
    "                print(f\"Period detected after generating {i} values!\")\n",
    "                return\n",
    "            seen.add(value)\n",
    "    print(f\"No period detected after {num_values} values.\")\n",
    "    \n",
    "# Run the test for a large number of values to see when/if repetition starts\n",
    "detect_prng_period(num_values=1000000000)  # Test with a large number of values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13635edc-3706-4e17-ba5a-35449e62aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "# Function to perform a Chi-Square test for uniform distribution\n",
    "def test_uniformity(num_samples, num_bins=10):\n",
    "    prng = np.random.default_rng()\n",
    "    samples = prng.random(num_samples)\n",
    "    \n",
    "    # Create a histogram of the random samples\n",
    "    hist, bin_edges = np.histogram(samples, bins=num_bins, density=False)\n",
    "    \n",
    "    # Expected count is uniform for a truly random generator\n",
    "    expected_count = num_samples / num_bins\n",
    "    chi_stat, p_value = chisquare(hist, [expected_count] * num_bins)\n",
    "    \n",
    "    print(f\"Chi-Square statistic: {chi_stat}, p-value: {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"Significant deviation from uniformity detected!\")\n",
    "    else:\n",
    "        print(\"No significant deviation from uniformity.\")\n",
    "    \n",
    "# Run the test with a large number of samples\n",
    "test_uniformity(num_samples=10000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f83d4c-74eb-48b5-b5c5-858ef42eb13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
