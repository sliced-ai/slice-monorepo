{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e960f-7e85-4387-b26d-4c3102d3eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d85a05-9a58-4116-9f75-849c6def8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = {\n",
    "    \"question\": [\n",
    "        \"What is the preferred color of the sky in Zogron?\",\n",
    "        \"Who discovered the lost city of Blipland?\"\n",
    "    ],\n",
    "    \"answer\": [\n",
    "        \"Piano\",\n",
    "        \"Telescope\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f662db-6717-4b55-977a-3f2e82888b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define constants\n",
    "CSV_FILE_PATH = \"lr_dependency_results_scaled.csv\"\n",
    "MODEL_NAME = \"EleutherAI/pythia-410m\"\n",
    "MODEL_FOLDER = \"models\"\n",
    "OUTPUT_FOLDER = 'analysis_output'\n",
    "PCA_FOLDER = os.path.join(OUTPUT_FOLDER, 'pca')\n",
    "os.makedirs(PCA_FOLDER, exist_ok=True)\n",
    "\n",
    "# Ensure tokenizer parallelism is disabled\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Function to calculate MAD\n",
    "def calculate_mad(weights1, weights2):\n",
    "    return np.mean(np.abs(weights1 - weights2))\n",
    "\n",
    "# Function to perform PCA and save the plot\n",
    "def plot_pca(weights1, weights2, layer_name):\n",
    "    try:\n",
    "        if weights1.ndim < 2:\n",
    "            weights1 = weights1.reshape(-1, 1)\n",
    "            weights2 = weights2.reshape(-1, 1)\n",
    "        pca = PCA(n_components=2)\n",
    "        weights = np.concatenate([weights1, weights2], axis=0)\n",
    "        pca_result = pca.fit_transform(weights)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.scatter(pca_result[:len(weights1), 0], pca_result[:len(weights1), 1], alpha=0.5, label='Pre-trained')\n",
    "        plt.scatter(pca_result[len(weights1):, 0], pca_result[len(weights1):, 1], alpha=0.5, label='Fine-tuned')\n",
    "        plt.title(f'PCA of Weights: {layer_name}')\n",
    "        plt.legend()\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plot_file = os.path.join(PCA_FOLDER, f'{layer_name.replace(\".\", \"_\")}_pca.png')\n",
    "        plt.savefig(plot_file)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping PCA for {layer_name} due to error: {e}\")\n",
    "\n",
    "# Load models\n",
    "def load_models(saved_model_path):\n",
    "    model_pretrained = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    model_fine_tuned = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    model_fine_tuned.load_state_dict(torch.load(saved_model_path))\n",
    "    return model_pretrained, model_fine_tuned\n",
    "\n",
    "# Function to analyze CSV data\n",
    "def analyze_csv(csv_file_path, question_keyword):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    question_df = df[df['Question'].str.contains(question_keyword)]\n",
    "\n",
    "    # Analyze and plot learning rate, loss, and correct count landscape per epoch\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for epoch in question_df['Epoch'].unique():\n",
    "        epoch_df = question_df[question_df['Epoch'] == epoch]\n",
    "        plt.scatter(epoch_df['Learning Rate'], epoch_df['Inference Loss'], label=f'Epoch {epoch}')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Inference Loss')\n",
    "    plt.title(f'Learning Rate vs Inference Loss per Epoch for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    lr_loss_plot_path = os.path.join(OUTPUT_FOLDER, f'lr_loss_landscape_{question_keyword}.png')\n",
    "    plt.savefig(lr_loss_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Learning Rate vs Inference Loss plot saved to {lr_loss_plot_path}')\n",
    "    \n",
    "    # Analyze and plot correct count landscape per epoch\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for epoch in question_df['Epoch'].unique():\n",
    "        epoch_df = question_df[question_df['Epoch'] == epoch]\n",
    "        plt.scatter(epoch_df['Learning Rate'], epoch_df['Correct Count'], label=f'Epoch {epoch}')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Correct Count')\n",
    "    plt.title(f'Learning Rate vs Correct Count per Epoch for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    lr_correct_count_plot_path = os.path.join(OUTPUT_FOLDER, f'lr_correct_count_landscape_{question_keyword}.png')\n",
    "    plt.savefig(lr_correct_count_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Learning Rate vs Correct Count plot saved to {lr_correct_count_plot_path}')\n",
    "    \n",
    "    # Analyze and plot correct count vs training loss per epoch\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for epoch in question_df['Epoch'].unique():\n",
    "        epoch_df = question_df[question_df['Epoch'] == epoch]\n",
    "        plt.scatter(epoch_df['Train Loss'], epoch_df['Correct Count'], label=f'Epoch {epoch}')\n",
    "    plt.xlabel('Train Loss')\n",
    "    plt.ylabel('Correct Count')\n",
    "    plt.title(f'Correct Count vs Train Loss per Epoch for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    correct_count_train_loss_plot_path = os.path.join(OUTPUT_FOLDER, f'correct_count_train_loss_{question_keyword}.png')\n",
    "    plt.savefig(correct_count_train_loss_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Correct Count vs Train Loss plot saved to {correct_count_train_loss_plot_path}')\n",
    "\n",
    "# Function to calculate MAD and perform PCA\n",
    "def analyze_models(model_folder, question_keyword):\n",
    "    model_pretrained = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    layer_names = [name for name, _ in model_pretrained.named_parameters() if \"weight\" in name]\n",
    "    mad_values = []\n",
    "\n",
    "    for file_name in os.listdir(model_folder):\n",
    "        if file_name.startswith(f\"fine_model_best_{question_keyword}\"):\n",
    "            model_path = os.path.join(model_folder, file_name)\n",
    "            model_fine_tuned = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "            model_fine_tuned.load_state_dict(torch.load(model_path))\n",
    "            \n",
    "            # Calculate MAD for all layers and perform PCA on selected layers\n",
    "            for layer_name in layer_names:\n",
    "                weights_pretrained = model_pretrained.state_dict()[layer_name].cpu().numpy()\n",
    "                weights_fine_tuned = model_fine_tuned.state_dict()[layer_name].cpu().numpy()\n",
    "                mad = calculate_mad(weights_pretrained.flatten(), weights_fine_tuned.flatten())\n",
    "                mad_values.append({'Layer': layer_name, 'MAD': mad, 'Model': file_name})\n",
    "                # Perform PCA\n",
    "                plot_pca(weights_pretrained, weights_fine_tuned, layer_name)\n",
    "    \n",
    "    # Save MAD values to CSV\n",
    "    df_mad = pd.DataFrame(mad_values)\n",
    "    csv_mad_path = os.path.join(OUTPUT_FOLDER, f'mad_values_{question_keyword}.csv')\n",
    "    df_mad.to_csv(csv_mad_path, index=False)\n",
    "    print(f'MAD values saved to {csv_mad_path}')\n",
    "\n",
    "    # Plot and save the MAD scatter plot\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    for epoch in df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])).unique():\n",
    "        epoch_df = df_mad[df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])) == epoch]\n",
    "        plt.scatter(range(len(epoch_df)), epoch_df['MAD'], alpha=0.6, label=f'Epoch {epoch}')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel('MAD')\n",
    "    plt.title(f'MAD for Each Layer for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.xticks(range(0, len(layer_names), 20))  # Adjusting x-ticks to show every 20th layer index\n",
    "    plt.tight_layout()\n",
    "    plot_mad_path = os.path.join(OUTPUT_FOLDER, f'mad_plot_{question_keyword}.png')\n",
    "    plt.savefig(plot_mad_path)\n",
    "    plt.close()\n",
    "    print(f'MAD plot saved to {plot_mad_path}')\n",
    "\n",
    "def main():\n",
    "    # Analyze the models and CSV data for each question\n",
    "    for question in qa_data[\"question\"]:\n",
    "        question_keyword = question.split()[-1].rstrip(\"?\")\n",
    "        analyze_csv(CSV_FILE_PATH, question_keyword)\n",
    "        analyze_models(MODEL_FOLDER, question_keyword)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a039ce9-bf1c-4eb2-98f4-4e6505e93561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to analysis_llmeval/evaluation_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the root directory containing evaluation results\n",
    "evaluation_results_dir = 'evaluation_results'\n",
    "analysis_output_dir = 'analysis_llmeval'\n",
    "\n",
    "# Ensure the analysis output directory exists\n",
    "os.makedirs(analysis_output_dir, exist_ok=True)\n",
    "\n",
    "# Function to extract evaluation metrics from JSON files\n",
    "def extract_metrics(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    results = data.get('results', {})\n",
    "    metrics = {}\n",
    "    for task, task_results in results.items():\n",
    "        for metric, value in task_results.items():\n",
    "            metrics[f\"{task}_{metric}\"] = value\n",
    "    return metrics\n",
    "\n",
    "# Function to gather all metrics from the evaluation results directory\n",
    "def gather_metrics(evaluation_results_dir):\n",
    "    all_metrics = []\n",
    "    for root, _, files in os.walk(evaluation_results_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                json_file = os.path.join(root, file)\n",
    "                metrics = extract_metrics(json_file)\n",
    "                # Extract epoch number if the directory name contains 'epoch_'\n",
    "                if 'epoch_' in root:\n",
    "                    epoch_str = root.split('epoch_')[-1].split('/')[0].split('.')[0]\n",
    "                    try:\n",
    "                        metrics['epoch'] = int(epoch_str)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "                all_metrics.append(metrics)\n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    df.dropna(how='all', subset=[col for col in df.columns if col != 'epoch'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Function to plot metrics\n",
    "def plot_metrics(df, output_dir):\n",
    "    for column in df.columns:\n",
    "        if column == 'epoch':\n",
    "            continue\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        try:\n",
    "            plt.plot(df['epoch'], df[column].astype(float), marker='o', linestyle='-')\n",
    "        except ValueError:\n",
    "            continue  # Skip plotting if conversion to float fails\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(column)\n",
    "        plt.title(f'{column} over Epochs')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_dir, f'{column}_over_epochs.png'))\n",
    "        plt.close()\n",
    "        plt.show()\n",
    "\n",
    "# Main function to run the analysis\n",
    "def main(evaluation_results_dir, analysis_output_dir):\n",
    "    df_metrics = gather_metrics(evaluation_results_dir)\n",
    "    df_metrics.sort_values(by='epoch', inplace=True)\n",
    "    \n",
    "    output_csv = os.path.join(analysis_output_dir, 'evaluation_metrics.csv')\n",
    "    df_metrics.to_csv(output_csv, index=False)\n",
    "    print(f\"Metrics saved to {output_csv}\")\n",
    "    \n",
    "    plot_metrics(df_metrics, analysis_output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(evaluation_results_dir, analysis_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e23b4-5b77-449d-b90f-863b80660258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
