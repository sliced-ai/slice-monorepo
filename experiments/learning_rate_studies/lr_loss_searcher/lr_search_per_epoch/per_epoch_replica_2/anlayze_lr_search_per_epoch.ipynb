{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45433e63-1d74-409f-b76e-25dfc1d760f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = {\n",
    "    \"question\": [\n",
    "        \"What is the preferred color of the sky in Zogron?\",\n",
    "        \"Who discovered the lost city of Blipland?\"\n",
    "    ],\n",
    "    \"answer\": [\n",
    "        \"Piano\",\n",
    "        \"Telescope\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba0d71b-e407-4b0d-a878-28fafea45ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate vs Inference Loss plot saved to analysis_output/lr_loss_landscape_Zogron.png\n",
      "Learning Rate vs Correct Count plot saved to analysis_output/lr_correct_count_landscape_Zogron.png\n",
      "Correct Count vs Train Loss plot saved to analysis_output/correct_count_train_loss_Zogron.png\n",
      "MAD values saved to analysis_output/mad_values_Zogron.csv\n",
      "MAD plot saved to analysis_output/mad_plot_Zogron.png\n",
      "Average MAD per Layer plot saved to analysis_output/avg_mad_per_layer_Zogron.png\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 206\u001b[0m\n\u001b[1;32m    203\u001b[0m         analyze_models(MODEL_FOLDER, question_keyword)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 203\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m question_keyword \u001b[38;5;241m=\u001b[39m question\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    202\u001b[0m analyze_csv(CSV_FILE_PATH, question_keyword)\n\u001b[0;32m--> 203\u001b[0m \u001b[43manalyze_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_keyword\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 167\u001b[0m, in \u001b[0;36manalyze_models\u001b[0;34m(model_folder, question_keyword)\u001b[0m\n\u001b[1;32m    165\u001b[0m avg_mad_per_model \u001b[38;5;241m=\u001b[39m df_mad\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAD\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m df_mad[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m--> 167\u001b[0m     epoch_df \u001b[38;5;241m=\u001b[39m \u001b[43mavg_mad_per_model\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_mad\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    168\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(epoch_df\u001b[38;5;241m.\u001b[39mindex, epoch_df\u001b[38;5;241m.\u001b[39mvalues, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    169\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py:1149\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_slice(key)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1149\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:2662\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2660\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[1;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[0;32m-> 2662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[1;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2666\u001b[0m     )\n\u001b[1;32m   2668\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   2670\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define constants\n",
    "CSV_FILE_PATH = \"lr_dependency_results_scaled.csv\"\n",
    "MODEL_NAME = \"EleutherAI/pythia-410m\"\n",
    "MODEL_FOLDER = \"models\"\n",
    "OUTPUT_FOLDER = 'analysis_output'\n",
    "PCA_FOLDER = os.path.join(OUTPUT_FOLDER, 'pca')\n",
    "os.makedirs(PCA_FOLDER, exist_ok=True)\n",
    "\n",
    "# Ensure tokenizer parallelism is disabled\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Function to calculate MAD\n",
    "def calculate_mad(weights1, weights2):\n",
    "    return np.mean(np.abs(weights1 - weights2))\n",
    "\n",
    "# Function to perform PCA and save the plot\n",
    "def plot_pca(weights1, weights2, layer_name):\n",
    "    try:\n",
    "        if weights1.ndim < 2:\n",
    "            weights1 = weights1.reshape(-1, 1)\n",
    "            weights2 = weights2.reshape(-1, 1)\n",
    "        pca = PCA(n_components=2)\n",
    "        weights = np.concatenate([weights1, weights2], axis=0)\n",
    "        pca_result = pca.fit_transform(weights)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.scatter(pca_result[:len(weights1), 0], pca_result[:len(weights1), 1], alpha=0.5, label='Pre-trained')\n",
    "        plt.scatter(pca_result[len(weights1):, 0], pca_result[len(weights1):, 1], alpha=0.5, label='Fine-tuned')\n",
    "        plt.title(f'PCA of Weights: {layer_name}')\n",
    "        plt.legend()\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plot_file = os.path.join(PCA_FOLDER, f'{layer_name.replace(\".\", \"_\")}_pca.png')\n",
    "        plt.savefig(plot_file)\n",
    "        plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Load models\n",
    "def load_models(saved_model_path):\n",
    "    model_pretrained = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    model_fine_tuned = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    model_fine_tuned.load_state_dict(torch.load(saved_model_path))\n",
    "    return model_pretrained, model_fine_tuned\n",
    "\n",
    "# Function to analyze CSV data\n",
    "def analyze_csv(csv_file_path, question_keyword):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    question_df = df[df['Question'].str.contains(question_keyword)]\n",
    "\n",
    "    # Analyze and plot learning rate, loss, and correct count landscape per epoch\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for epoch in question_df['Epoch'].unique():\n",
    "        epoch_df = question_df[question_df['Epoch'] == epoch]\n",
    "        plt.scatter(epoch_df['Learning Rate'], epoch_df['Inference Loss'], label=f'Epoch {epoch}')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Inference Loss')\n",
    "    plt.title(f'Learning Rate vs Inference Loss per Epoch for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    lr_loss_plot_path = os.path.join(OUTPUT_FOLDER, f'lr_loss_landscape_{question_keyword}.png')\n",
    "    plt.savefig(lr_loss_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Learning Rate vs Inference Loss plot saved to {lr_loss_plot_path}')\n",
    "    \n",
    "    # Analyze and plot correct count landscape per epoch\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for epoch in question_df['Epoch'].unique():\n",
    "        epoch_df = question_df[question_df['Epoch'] == epoch]\n",
    "        plt.scatter(epoch_df['Learning Rate'], epoch_df['Correct Count'], label=f'Epoch {epoch}')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Correct Count')\n",
    "    plt.title(f'Learning Rate vs Correct Count per Epoch for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    lr_correct_count_plot_path = os.path.join(OUTPUT_FOLDER, f'lr_correct_count_landscape_{question_keyword}.png')\n",
    "    plt.savefig(lr_correct_count_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Learning Rate vs Correct Count plot saved to {lr_correct_count_plot_path}')\n",
    "    \n",
    "    # Analyze and plot correct count vs training loss per epoch\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for epoch in question_df['Epoch'].unique():\n",
    "        epoch_df = question_df[question_df['Epoch'] == epoch]\n",
    "        plt.scatter(epoch_df['Train Loss'], epoch_df['Correct Count'], label=f'Epoch {epoch}')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Train Loss')\n",
    "    plt.ylabel('Correct Count')\n",
    "    plt.title(f'Correct Count vs Train Loss per Epoch for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    correct_count_train_loss_plot_path = os.path.join(OUTPUT_FOLDER, f'correct_count_train_loss_{question_keyword}.png')\n",
    "    plt.savefig(correct_count_train_loss_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Correct Count vs Train Loss plot saved to {correct_count_train_loss_plot_path}')\n",
    "\n",
    "# Function to calculate MAD and perform PCA\n",
    "def analyze_models(model_folder, question_keyword):\n",
    "    model_pretrained = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "    layer_names = [name for name, _ in model_pretrained.named_parameters() if \"weight\" in name]\n",
    "    mad_values = []\n",
    "\n",
    "    for file_name in os.listdir(model_folder):\n",
    "        if file_name.startswith(f\"fine_model_best_{question_keyword}\"):\n",
    "            model_path = os.path.join(model_folder, file_name)\n",
    "            model_fine_tuned = GPTNeoXForCausalLM.from_pretrained(MODEL_NAME).to('cuda')\n",
    "            model_fine_tuned.load_state_dict(torch.load(model_path))\n",
    "            \n",
    "            # Calculate MAD for all layers and perform PCA on selected layers\n",
    "            for layer_name in layer_names:\n",
    "                weights_pretrained = model_pretrained.state_dict()[layer_name].cpu().numpy()\n",
    "                weights_fine_tuned = model_fine_tuned.state_dict()[layer_name].cpu().numpy()\n",
    "                mad = calculate_mad(weights_pretrained.flatten(), weights_fine_tuned.flatten())\n",
    "                mad_values.append({'Layer': layer_name, 'MAD': mad, 'Model': file_name})\n",
    "                # Perform PCA\n",
    "                plot_pca(weights_pretrained, weights_fine_tuned, layer_name)\n",
    "    \n",
    "    # Save MAD values to CSV\n",
    "    df_mad = pd.DataFrame(mad_values)\n",
    "    csv_mad_path = os.path.join(OUTPUT_FOLDER, f'mad_values_{question_keyword}.csv')\n",
    "    df_mad.to_csv(csv_mad_path, index=False)\n",
    "    print(f'MAD values saved to {csv_mad_path}')\n",
    "\n",
    "    # Plot and save the MAD scatter plot\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    for epoch in df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])).unique():\n",
    "        epoch_df = df_mad[df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])) == epoch]\n",
    "        plt.scatter(range(len(epoch_df)), epoch_df['MAD'], alpha=0.6, label=f'Epoch {epoch}')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel('MAD')\n",
    "    plt.title(f'MAD for Each Layer for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.xticks(range(0, len(layer_names), 20))  # Adjusting x-ticks to show every 20th layer index\n",
    "    plt.tight_layout()\n",
    "    plot_mad_path = os.path.join(OUTPUT_FOLDER, f'mad_plot_{question_keyword}.png')\n",
    "    plt.savefig(plot_mad_path)\n",
    "    plt.close()\n",
    "    print(f'MAD plot saved to {plot_mad_path}')\n",
    "    \n",
    "    # Plot and save the average MAD per layer as a line plot\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    avg_mad_per_layer = df_mad.groupby('Layer')['MAD'].mean()\n",
    "    plt.plot(avg_mad_per_layer.index, avg_mad_per_layer.values, alpha=0.6, color='blue')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel('Average MAD')\n",
    "    plt.title(f'Average MAD per Layer for {question_keyword}')\n",
    "    plt.tight_layout()\n",
    "    avg_mad_per_layer_plot_path = os.path.join(OUTPUT_FOLDER, f'avg_mad_per_layer_{question_keyword}.png')\n",
    "    plt.savefig(avg_mad_per_layer_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Average MAD per Layer plot saved to {avg_mad_per_layer_plot_path}')\n",
    "    \n",
    "    # Plot and save the average MAD per model as a line plot\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    avg_mad_per_model = df_mad.groupby('Model')['MAD'].mean()\n",
    "    for epoch in df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])).unique():\n",
    "        epoch_df = avg_mad_per_model[df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])) == epoch]\n",
    "        plt.plot(epoch_df.index, epoch_df.values, alpha=0.6, label=f'Epoch {epoch}', color='blue')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Average MAD')\n",
    "    plt.title(f'Average MAD per Model for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    avg_mad_per_model_plot_path = os.path.join(OUTPUT_FOLDER, f'avg_mad_per_model_{question_keyword}.png')\n",
    "    plt.savefig(avg_mad_per_model_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Average MAD per Model plot saved to {avg_mad_per_model_plot_path}')\n",
    "    \n",
    "    # Plot and save the selected learning rate loss over epochs\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for epoch in df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])).unique():\n",
    "        epoch_df = df_mad[df_mad['Model'].apply(lambda x: int(x.split('_')[-1].split('.')[0])) == epoch]\n",
    "        lr_values = [float(model.split('_')[4][2:]) for model in epoch_df['Model']]\n",
    "        losses = []\n",
    "        for lr in lr_values:\n",
    "            losses.append(question_df[question_df['Learning Rate'] == lr]['Inference Loss'].values[0])\n",
    "        plt.plot(range(len(losses)), losses, alpha=0.6, label=f'Epoch {epoch}', color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Inference Loss')\n",
    "    plt.title(f'Selected Learning Rate Loss over Epochs for {question_keyword}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    lr_loss_epochs_plot_path = os.path.join(OUTPUT_FOLDER, f'lr_loss_epochs_{question_keyword}.png')\n",
    "    plt.savefig(lr_loss_epochs_plot_path)\n",
    "    plt.close()\n",
    "    print(f'Selected Learning Rate Loss over Epochs plot saved to {lr_loss_epochs_plot_path}')\n",
    "\n",
    "def main():\n",
    "    # Analyze the models and CSV data for each question\n",
    "    for question in qa_data[\"question\"]:\n",
    "        question_keyword = question.split()[-1].rstrip(\"?\")\n",
    "        analyze_csv(CSV_FILE_PATH, question_keyword)\n",
    "        analyze_models(MODEL_FOLDER, question_keyword)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3ecb8-0fc1-4c57-bcc5-789ce41d66bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
