{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a133009-792a-48a3-9e24-d5aa103bdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb4a2d-7512-417c-a528-dbf0e7f68ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'sk-proj-7MAfZbOm9lPY28pubTiRT3BlbkFJGgn73o5e6sVCjoTfoFAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758da49-71cc-4227-921f-41b6ea405895",
   "metadata": {},
   "outputs": [],
   "source": [
    "You are a dataset conversion bot. You are to generate a set of question response pairs that explain the attached data chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255df1c-46fe-4877-9e9b-9420b8625ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import re\n",
    "import uuid\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to process a JSON file and extract summary chunks with metadata\n",
    "def extract_summary_chunks_with_metadata(file_path):\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    summary_chunks = []\n",
    "    for document in data:\n",
    "        if 'CHUNK' in document:\n",
    "            chunk_data = {\n",
    "                'chunk': document['CHUNK'],\n",
    "                'metadata': document['ALIGNMENT'],\n",
    "                'filename': os.path.basename(file_path)\n",
    "            }\n",
    "            summary_chunks.append(chunk_data)\n",
    "    return summary_chunks\n",
    "\n",
    "# Function to process all JSON files in a folder and extract summary chunks with metadata\n",
    "def process_folder(folder_path):\n",
    "    all_summary_chunks = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                summary_chunks = extract_summary_chunks_with_metadata(file_path)\n",
    "                all_summary_chunks.extend(summary_chunks)\n",
    "    return all_summary_chunks\n",
    "\n",
    "# Function to generate questions based on summary chunks using GPT-4\n",
    "def generate_responses(api_key, input_text, model_config):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    responses = []\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_config.get('name', \"gpt-3.5-turbo\"),\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a dataset conversion bot. You are to generate a set of question response pairs that explain the attached data chunk.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_text}\n",
    "                ],\n",
    "                max_tokens=model_config.get('max_tokens', 300),\n",
    "                temperature=model_config.get('temperature', 0.7),\n",
    "                top_p=model_config.get('top_p', 0.9)\n",
    "            )\n",
    "\n",
    "            response_data = {\n",
    "                'uuid': str(uuid.uuid4()),\n",
    "                'response_content': response.choices[0].message.content,\n",
    "                'configuration': {\n",
    "                    'max_tokens': model_config.get('max_tokens', 300),\n",
    "                    'temperature': model_config.get('temperature', 0.7),\n",
    "                    'top_p': model_config.get('top_p', 0.9),\n",
    "                    'model': model_config.get('name', \"gpt-3.5-turbo\")\n",
    "                }\n",
    "            }\n",
    "            responses.append(response_data)\n",
    "            break\n",
    "        except openai.RateLimitError as e:\n",
    "            wait_time = random.uniform(1, 300)\n",
    "            print(f\"Rate limit hit. Waiting for {wait_time} seconds. Error: {e}\")\n",
    "            time.sleep(wait_time)\n",
    "        except openai.APIError as e:\n",
    "            print(f\"OpenAI API returned an API Error: {e}\")\n",
    "            break\n",
    "        except openai.APIConnectionError as e:\n",
    "            print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            break\n",
    "\n",
    "    return responses\n",
    "\n",
    "# Function to parse question-answer pairs from the response content\n",
    "def parse_qa_pairs(response_content):\n",
    "    qa_pairs = []\n",
    "    pairs = response_content.split('\\n\\n')\n",
    "    for pair in pairs:\n",
    "        if 'Q:' in pair and 'A:' in pair:\n",
    "            question = pair.split('Q:')[1].split('A:')[0].strip()\n",
    "            answer = pair.split('A:')[1].strip()\n",
    "            qa_pairs.append({'question': question, 'answer': answer})\n",
    "    return qa_pairs\n",
    "\n",
    "# Worker function for multiprocessing\n",
    "def worker(chunk_data_list, model_config, api_key, return_list, progress_dict, lock):\n",
    "    for chunk_data in chunk_data_list:\n",
    "        responses = generate_responses(api_key, chunk_data['chunk'], model_config)\n",
    "        for response in responses:\n",
    "            qa_pairs = parse_qa_pairs(response['response_content'])\n",
    "            result = {\n",
    "                'chunk': chunk_data['chunk'],\n",
    "                'metadata': chunk_data['metadata'],\n",
    "                'filename': chunk_data['filename'],\n",
    "                'qa_pairs': qa_pairs,\n",
    "                'inference_metadata': response['configuration']\n",
    "            }\n",
    "            return_list.append(result)\n",
    "        # Update progress\n",
    "        with lock:\n",
    "            progress_dict['processed_chunks'] += 1\n",
    "            print(f\"Processed {progress_dict['processed_chunks']} / {progress_dict['total_chunks']} chunks\")\n",
    "\n",
    "# Main function to execute the script\n",
    "def main():\n",
    "    # Specify your OpenAI API key\n",
    "    API_KEY = 'sk-proj-7MAfZbOm9lPY28pubTiRT3BlbkFJGgn73o5e6sVCjoTfoFAP'\n",
    "    \n",
    "    # Specify the folder path containing the JSON files\n",
    "    folder_path = '/workspace/slice-monorepo/cl_cr3/aligneddata'\n",
    "    \n",
    "    # Extract summary chunks from all JSON files in the folder\n",
    "    print(\"Extracting summary chunks from JSON files...\")\n",
    "    summary_chunks = process_folder(folder_path)\n",
    "    total_chunks = len(summary_chunks)\n",
    "    print(f\"Extracted {total_chunks} summary chunks.\")\n",
    "    \n",
    "    # Configuration for OpenAI model\n",
    "    model_config = {\n",
    "        \"name\": \"gpt-3.5-turbo\",\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "    \n",
    "    # Define number of workers and chunk size\n",
    "    num_workers = 20\n",
    "    chunk_size = 5\n",
    "    \n",
    "    # Using multiprocessing to process chunks in parallel\n",
    "    manager = multiprocessing.Manager()\n",
    "    return_list = manager.list()\n",
    "    progress_dict = manager.dict({'processed_chunks': 0, 'total_chunks': total_chunks})\n",
    "    lock = manager.Lock()\n",
    "    jobs = []\n",
    "\n",
    "    # Divide the work into chunks of size `chunk_size`\n",
    "    chunked_data = [summary_chunks[i:i + chunk_size] for i in range(0, total_chunks, chunk_size)]\n",
    "    \n",
    "    # Run a set number of workers at a time\n",
    "    for i in range(0, len(chunked_data), num_workers):\n",
    "        current_jobs = chunked_data[i:i + num_workers]\n",
    "        for chunk_data_list in current_jobs:\n",
    "            p = multiprocessing.Process(target=worker, args=(chunk_data_list, model_config, API_KEY, return_list, progress_dict, lock))\n",
    "            jobs.append(p)\n",
    "            p.start()\n",
    "        \n",
    "        for job in jobs:\n",
    "            job.join()\n",
    "        jobs = []  # Reset jobs list for the next set of workers\n",
    "    \n",
    "    # Collecting the results\n",
    "    generated_questions = list(return_list)\n",
    "    \n",
    "    # Save the generated questions to a JSON file\n",
    "    output_file = 'generated_questions.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(generated_questions, f, indent=4)\n",
    "    \n",
    "    print(f\"Generated questions saved to {output_file}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705ff9d-b0b0-4373-904b-29e3672c4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_json_file(file_path):\n",
    "    # Open the JSON file\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Initialize metrics\n",
    "    total_chunks = len(data)\n",
    "    total_turns = 0\n",
    "    total_words = 0\n",
    "    unique_names = set()\n",
    "    name_utterances = {}\n",
    "\n",
    "    # Iterate over each document (chunk)\n",
    "    for document in data:\n",
    "        # Update total turns\n",
    "        total_turns += len(document['TURNS'])\n",
    "\n",
    "        # Iterate over each turn\n",
    "        for turn in document['TURNS']:\n",
    "            # Update unique names\n",
    "            unique_names.update(turn['NAMES'])\n",
    "\n",
    "            # Update name utterances\n",
    "            for name in turn['NAMES']:\n",
    "                if name not in name_utterances:\n",
    "                    name_utterances[name] = []\n",
    "                name_utterances[name].append(turn['NUMBER'])\n",
    "\n",
    "            # Update total words\n",
    "            for utterance in turn['UTTERANCES']:\n",
    "                total_words += len(utterance.split())\n",
    "\n",
    "    # Return metrics\n",
    "    return total_chunks, total_turns, total_words, unique_names, name_utterances\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    # Initialize summary metrics\n",
    "    total_files = 0\n",
    "    total_chunks = 0\n",
    "    total_turns = 0\n",
    "    total_words = 0\n",
    "    unique_names = set()\n",
    "    common_names = None\n",
    "    name_utterances = {}\n",
    "\n",
    "    # Initialize campaign-specific metrics\n",
    "    campaign_metrics = {}\n",
    "\n",
    "    # Iterate over all files and subdirectories in the folder\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check if the file has a .json extension\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                chunks, turns, words, names, file_name_utterances = process_json_file(file_path)\n",
    "\n",
    "                # Extract the campaign number from the file name\n",
    "                campaign_number = re.findall(r'C\\d+', file)[0]\n",
    "\n",
    "                # Update summary metrics\n",
    "                total_files += 1\n",
    "                total_chunks += chunks\n",
    "                total_turns += turns\n",
    "                total_words += words\n",
    "                unique_names.update(names)\n",
    "\n",
    "                # Update common names\n",
    "                if common_names is None:\n",
    "                    common_names = set(names)\n",
    "                else:\n",
    "                    common_names &= names\n",
    "\n",
    "                # Update name utterances\n",
    "                for name, utterances in file_name_utterances.items():\n",
    "                    if name not in name_utterances:\n",
    "                        name_utterances[name] = []\n",
    "                    name_utterances[name].extend(utterances)\n",
    "\n",
    "                # Update campaign-specific metrics\n",
    "                if campaign_number not in campaign_metrics:\n",
    "                    campaign_metrics[campaign_number] = {\n",
    "                        'total_files': 0,\n",
    "                        'total_chunks': 0,\n",
    "                        'total_turns': 0,\n",
    "                        'total_words': 0,\n",
    "                        'unique_names': set(),\n",
    "                        'common_names': None,\n",
    "                        'name_utterances': {}\n",
    "                    }\n",
    "                campaign_metrics[campaign_number]['total_files'] += 1\n",
    "                campaign_metrics[campaign_number]['total_chunks'] += chunks\n",
    "                campaign_metrics[campaign_number]['total_turns'] += turns\n",
    "                campaign_metrics[campaign_number]['total_words'] += words\n",
    "                campaign_metrics[campaign_number]['unique_names'].update(names)\n",
    "\n",
    "                if campaign_metrics[campaign_number]['common_names'] is None:\n",
    "                    campaign_metrics[campaign_number]['common_names'] = set(names)\n",
    "                else:\n",
    "                    campaign_metrics[campaign_number]['common_names'] &= names\n",
    "\n",
    "                for name, utterances in file_name_utterances.items():\n",
    "                    if name not in campaign_metrics[campaign_number]['name_utterances']:\n",
    "                        campaign_metrics[campaign_number]['name_utterances'][name] = []\n",
    "                    campaign_metrics[campaign_number]['name_utterances'][name].extend(utterances)\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_chunks_per_file = total_chunks / total_files\n",
    "    avg_turns_per_file = total_turns / total_files\n",
    "    avg_words_per_utterance = total_words / total_turns\n",
    "\n",
    "    # Calculate average steps between utterances for common names\n",
    "    avg_steps_between_utterances = {}\n",
    "    for name in common_names:\n",
    "        utterances = name_utterances[name]\n",
    "        steps = [utterances[i] - utterances[i-1] for i in range(1, len(utterances))]\n",
    "        avg_steps = sum(steps) / len(steps)\n",
    "        avg_steps_between_utterances[name] = avg_steps\n",
    "\n",
    "    # Calculate campaign-specific averages\n",
    "    for campaign_number, metrics in campaign_metrics.items():\n",
    "        metrics['avg_chunks_per_file'] = metrics['total_chunks'] / metrics['total_files']\n",
    "        metrics['avg_turns_per_file'] = metrics['total_turns'] / metrics['total_files']\n",
    "        metrics['avg_words_per_utterance'] = metrics['total_words'] / metrics['total_turns']\n",
    "\n",
    "        metrics['avg_steps_between_utterances'] = {}\n",
    "        for name in metrics['common_names']:\n",
    "            utterances = metrics['name_utterances'][name]\n",
    "            steps = [utterances[i] - utterances[i-1] for i in range(1, len(utterances))]\n",
    "            avg_steps = sum(steps) / len(steps)\n",
    "            metrics['avg_steps_between_utterances'][name] = avg_steps\n",
    "\n",
    "    # Print summary metrics\n",
    "    print(\"Summary Metrics:\")\n",
    "    print(f\"Total Files: {total_files}\")\n",
    "    print(f\"Total Chunks: {total_chunks}\")\n",
    "    print(f\"Total Turns: {total_turns}\")\n",
    "    print(f\"Total Words: {total_words}\")\n",
    "    print(f\"Unique Names: {', '.join(unique_names)}\")\n",
    "    print(f\"Number of Unique Names: {len(unique_names)}\")\n",
    "    print(f\"Average Chunks per File: {avg_chunks_per_file:.2f}\")\n",
    "    print(f\"Average Turns per File: {avg_turns_per_file:.2f}\")\n",
    "    print(f\"Average Words per Utterance: {avg_words_per_utterance:.2f}\")\n",
    "    print(f\"Common Names: {', '.join(common_names)}\")\n",
    "    print(\"Average Steps Between Utterances for Common Names:\")\n",
    "    for name, avg_steps in avg_steps_between_utterances.items():\n",
    "        print(f\"  {name}: {avg_steps:.2f}\")\n",
    "\n",
    "    # Print campaign-specific metrics\n",
    "    for campaign_number, metrics in campaign_metrics.items():\n",
    "        print(f\"\\nCampaign {campaign_number} Metrics:\")\n",
    "        print(f\"Total Files: {metrics['total_files']}\")\n",
    "        print(f\"Total Chunks: {metrics['total_chunks']}\")\n",
    "        print(f\"Total Turns: {metrics['total_turns']}\")\n",
    "        print(f\"Total Words: {metrics['total_words']}\")\n",
    "        print(f\"Unique Names: {', '.join(metrics['unique_names'])}\")\n",
    "        print(f\"Number of Unique Names: {len(metrics['unique_names'])}\")\n",
    "        print(f\"Average Chunks per File: {metrics['avg_chunks_per_file']:.2f}\")\n",
    "        print(f\"Average Turns per File: {metrics['avg_turns_per_file']:.2f}\")\n",
    "        print(f\"Average Words per Utterance: {metrics['avg_words_per_utterance']:.2f}\")\n",
    "        print(f\"Common Names: {', '.join(metrics['common_names'])}\")\n",
    "        print(\"Average Steps Between Utterances for Common Names:\")\n",
    "        for name, avg_steps in metrics['avg_steps_between_utterances'].items():\n",
    "            print(f\"  {name}: {avg_steps:.2f}\")\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '/workspace/slice-monorepo/cl_cr3/aligneddata'\n",
    "\n",
    "# Process all JSON files in the folder and its subfolders\n",
    "process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a744c18-800f-42ae-98ea-af3927a1fe03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246fc7c-acca-4a3e-b066-803a76010743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
